# 12. Quality Reporting (í’ˆì§ˆ ë¦¬í¬íŠ¸)

**ìƒì„±ì¼**: 2025-01-26  
**ë²„ì „**: 1.0  
**ì¹´í…Œê³ ë¦¬**: Data Quality & Reporting

---

## 1. ê°œìš” (Overview)

### 1.1 ëª©ì  (Purpose)

í’ˆì§ˆ ë¦¬í¬íŒ…(Quality Reporting)ì€ ë°ì´í„° í´ë Œì§• ì „í›„ì˜ ë°ì´í„° í’ˆì§ˆì„ ë¹„êµí•˜ê³ , ê°œì„  ì‚¬í•­ì„ ì‹œê°í™”í•˜ì—¬ ì´í•´ê´€ê³„ìì—ê²Œ ì „ë‹¬í•˜ëŠ” í•„ìˆ˜ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. ì´ ë ˆí¼ëŸ°ìŠ¤ëŠ” ì¢…í•©ì ì¸ ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

### 1.2 ì ìš© ì‹œê¸° (When to Apply)

**í•„ìˆ˜ ì ìš© ì‹œì **:
- âœ… ë°ì´í„° í´ë Œì§• ì‘ì—… ì™„ë£Œ í›„
- âœ… í”„ë¡œì íŠ¸ ë§ˆì¼ìŠ¤í†¤ ë‹¬ì„± ì‹œ
- âœ… ì´í•´ê´€ê³„ì ë³´ê³  ì‹œ
- âœ… ë°ì´í„° í’ˆì§ˆ ê°ì‚¬(audit) ì‹œ

**ì •ê¸° ì ìš©**:
- ğŸ”¹ ì£¼ê°„/ì›”ê°„ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
- ğŸ”¹ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„
- ğŸ”¹ í”„ë¡œë•ì…˜ ë°°í¬ ì „ ìµœì¢… ê²€ì¦

### 1.3 ë¦¬í¬íŠ¸ ìœ í˜• (Report Types)

```
Type 1: Executive Summary (ê²½ì˜ì§„ìš©)
â””â”€â”€ í•µì‹¬ ë©”íŠ¸ë¦­, ê°œì„ ìœ¨, íˆ¬ì ëŒ€ë¹„ íš¨ê³¼

Type 2: Technical Report (ê¸°ìˆ íŒ€ìš©)
â””â”€â”€ ìƒì„¸ í†µê³„, ì•Œê³ ë¦¬ì¦˜, ì½”ë“œ ì‹¤í–‰ ë¡œê·¸

Type 3: Operational Dashboard (ìš´ì˜íŒ€ìš©)
â””â”€â”€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§, ê²½ê³ (alert), íŠ¸ë Œë“œ

Type 4: Audit Report (ê°ì‚¬ìš©)
â””â”€â”€ ë³€ê²½ ì´ë ¥, ìŠ¹ì¸ ê¸°ë¡, ê·œì • ì¤€ìˆ˜
```

---

## 2. ì´ë¡ ì  ë°°ê²½ (Theoretical Background)

### 2.1 ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­

**ê¸°ë³¸ ë©”íŠ¸ë¦­ (Basic Metrics)**:
1. **Completeness** (ì™„ì „ì„±)
   - ê²°ì¸¡ë¥  (Missing Rate): `(ê²°ì¸¡ê°’ ê°œìˆ˜ / ì „ì²´ ê°’) Ã— 100`
   - ë ˆì½”ë“œ ì™„ì „ì„±: `(ì™„ì „í•œ ë ˆì½”ë“œ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`

2. **Accuracy** (ì •í™•ì„±)
   - ì˜¤ë¥˜ìœ¨ (Error Rate): `(ì˜¤ë¥˜ ê°œìˆ˜ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`
   - ê²€ì¦ í†µê³¼ìœ¨: `(í†µê³¼ ë ˆì½”ë“œ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`

3. **Consistency** (ì¼ê´€ì„±)
   - ë¶ˆì¼ì¹˜ìœ¨: `(ë¶ˆì¼ì¹˜ ë ˆì½”ë“œ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`
   - ì°¸ì¡° ë¬´ê²°ì„±: `(ê³ ì•„ ë ˆì½”ë“œ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`

4. **Uniqueness** (ìœ ì¼ì„±)
   - ì¤‘ë³µë¥ : `(ì¤‘ë³µ ë ˆì½”ë“œ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`
   - í‚¤ ìœ ì¼ì„±: `(ìœ ë‹ˆí¬ í‚¤ / ì „ì²´ ë ˆì½”ë“œ) Ã— 100`

**ê³ ê¸‰ ë©”íŠ¸ë¦­ (Advanced Metrics)**:
- **Data Quality Score** (ì¢…í•© í’ˆì§ˆ ì ìˆ˜): ê°€ì¤‘ í‰ê· 
- **Improvement Rate** (ê°œì„ ìœ¨): `(After - Before) / Before Ã— 100`
- **ROI** (íˆ¬ì ëŒ€ë¹„ íš¨ê³¼): `(ê°œì„  ê°€ì¹˜ / íˆ¬ì… ë¹„ìš©) Ã— 100`

### 2.2 ë¦¬í¬íŠ¸ êµ¬ì¡°

**í‘œì¤€ ë¦¬í¬íŠ¸ êµ¬ì¡°**:
```
1. Executive Summary (ìš”ì•½)
   â”œâ”€â”€ í•µì‹¬ ë°œê²¬ì‚¬í•­ (Key Findings)
   â”œâ”€â”€ ê¶Œì¥ì‚¬í•­ (Recommendations)
   â””â”€â”€ ë‹¤ìŒ ë‹¨ê³„ (Next Steps)

2. Data Overview (ë°ì´í„° ê°œìš”)
   â”œâ”€â”€ ë°ì´í„° ì†ŒìŠ¤
   â”œâ”€â”€ ì²˜ë¦¬ ê¸°ê°„
   â””â”€â”€ ë°ì´í„° ë³¼ë¥¨

3. Quality Metrics (í’ˆì§ˆ ë©”íŠ¸ë¦­)
   â”œâ”€â”€ Before/After ë¹„êµ
   â”œâ”€â”€ ê°œì„ ìœ¨
   â””â”€â”€ ëª©í‘œ ë‹¬ì„±ë„

4. Detailed Analysis (ìƒì„¸ ë¶„ì„)
   â”œâ”€â”€ ì»¬ëŸ¼ë³„ í’ˆì§ˆ
   â”œâ”€â”€ ìœ„ë°˜ ì‚¬í•­
   â””â”€â”€ íŒ¨í„´ ë¶„ì„

5. Visualizations (ì‹œê°í™”)
   â”œâ”€â”€ ì°¨íŠ¸ ë° ê·¸ë˜í”„
   â”œâ”€â”€ íˆíŠ¸ë§µ
   â””â”€â”€ íŠ¸ë Œë“œ ë¶„ì„

6. Recommendations (ê¶Œì¥ì‚¬í•­)
   â”œâ”€â”€ ê°œì„  í•„ìš” ì˜ì—­
   â”œâ”€â”€ ìš°ì„ ìˆœìœ„
   â””â”€â”€ ì•¡ì…˜ í”Œëœ
```

### 2.3 ì‹œê°í™” ì „ëµ

**íš¨ê³¼ì ì¸ ì‹œê°í™” ì„ íƒ**:
| ë°ì´í„° ìœ í˜• | ê¶Œì¥ ì‹œê°í™” | ëª©ì  |
|------------|------------|------|
| ì‹œê³„ì—´ ë³€í™” | Line Chart | íŠ¸ë Œë“œ íŒŒì•… |
| ë¹„ìœ¨ ë¹„êµ | Bar Chart | ì „í›„ ë¹„êµ |
| ë¶„í¬ | Histogram, Box Plot | ì´ìƒì¹˜ ë° ë¶„í¬ í™•ì¸ |
| ìƒê´€ê´€ê³„ | Heatmap | ë³€ìˆ˜ ê°„ ê´€ê³„ |
| êµ¬ì„± ë¹„ìœ¨ | Pie Chart | ì¹´í…Œê³ ë¦¬ë³„ ë¹„ì¤‘ |
| ë‹¤ì°¨ì› | Scatter Plot | íŒ¨í„´ ì‹ë³„ |

---

## 3. êµ¬í˜„ (Implementation)

### 3.1 í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°ê¸°

```python
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
from datetime import datetime

class DataQualityMetrics:
    """
    ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° í´ë˜ìŠ¤
    Calculate data quality metrics
    """
    
    def __init__(self, df_before: pd.DataFrame, df_after: pd.DataFrame):
        """
        Parameters:
        -----------
        df_before : pd.DataFrame
            í´ë Œì§• ì „ ë°ì´í„°
        df_after : pd.DataFrame
            í´ë Œì§• í›„ ë°ì´í„°
        """
        self.df_before = df_before.copy()
        self.df_after = df_after.copy()
        self.metrics = {}
        
    def calculate_completeness(self) -> Dict[str, Any]:
        """
        ì™„ì „ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
        Calculate completeness metrics
        
        Returns:
        --------
        metrics : dict
            ì™„ì „ì„± ê´€ë ¨ ë©”íŠ¸ë¦­
        """
        # Before ë©”íŠ¸ë¦­
        before_missing = self.df_before.isnull().sum().sum()
        before_total = self.df_before.size
        before_missing_rate = 100 * before_missing / before_total
        
        # After ë©”íŠ¸ë¦­
        after_missing = self.df_after.isnull().sum().sum()
        after_total = self.df_after.size
        after_missing_rate = 100 * after_missing / after_total
        
        # ê°œì„ ìœ¨
        improvement = before_missing - after_missing
        improvement_rate = 100 * improvement / before_missing if before_missing > 0 else 0
        
        metrics = {
            'before': {
                'missing_values': int(before_missing),
                'total_values': int(before_total),
                'missing_rate': round(before_missing_rate, 2),
                'completeness': round(100 - before_missing_rate, 2)
            },
            'after': {
                'missing_values': int(after_missing),
                'total_values': int(after_total),
                'missing_rate': round(after_missing_rate, 2),
                'completeness': round(100 - after_missing_rate, 2)
            },
            'improvement': {
                'values_filled': int(improvement),
                'improvement_rate': round(improvement_rate, 2)
            }
        }
        
        return metrics
    
    def calculate_uniqueness(self) -> Dict[str, Any]:
        """
        ìœ ì¼ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
        Calculate uniqueness metrics
        
        Returns:
        --------
        metrics : dict
            ìœ ì¼ì„± ê´€ë ¨ ë©”íŠ¸ë¦­
        """
        # Before ë©”íŠ¸ë¦­
        before_duplicates = self.df_before.duplicated().sum()
        before_duplicate_rate = 100 * before_duplicates / len(self.df_before)
        
        # After ë©”íŠ¸ë¦­
        after_duplicates = self.df_after.duplicated().sum()
        after_duplicate_rate = 100 * after_duplicates / len(self.df_after)
        
        # ê°œì„ ìœ¨
        improvement = before_duplicates - after_duplicates
        improvement_rate = 100 * improvement / before_duplicates if before_duplicates > 0 else 0
        
        metrics = {
            'before': {
                'duplicate_rows': int(before_duplicates),
                'total_rows': len(self.df_before),
                'duplicate_rate': round(before_duplicate_rate, 2),
                'uniqueness': round(100 - before_duplicate_rate, 2)
            },
            'after': {
                'duplicate_rows': int(after_duplicates),
                'total_rows': len(self.df_after),
                'duplicate_rate': round(after_duplicate_rate, 2),
                'uniqueness': round(100 - after_duplicate_rate, 2)
            },
            'improvement': {
                'duplicates_removed': int(improvement),
                'improvement_rate': round(improvement_rate, 2)
            }
        }
        
        return metrics
    
    def calculate_column_quality(self) -> pd.DataFrame:
        """
        ì»¬ëŸ¼ë³„ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
        Calculate quality metrics per column
        
        Returns:
        --------
        quality_df : pd.DataFrame
            ì»¬ëŸ¼ë³„ í’ˆì§ˆ ë¹„êµ í…Œì´ë¸”
        """
        common_cols = set(self.df_before.columns) & set(self.df_after.columns)
        
        results = []
        for col in common_cols:
            # Before ë©”íŠ¸ë¦­
            before_missing = self.df_before[col].isnull().sum()
            before_missing_rate = 100 * before_missing / len(self.df_before)
            before_unique = self.df_before[col].nunique()
            
            # After ë©”íŠ¸ë¦­
            after_missing = self.df_after[col].isnull().sum()
            after_missing_rate = 100 * after_missing / len(self.df_after)
            after_unique = self.df_after[col].nunique()
            
            # ê°œì„ 
            improvement = before_missing - after_missing
            
            results.append({
                'column': col,
                'dtype': str(self.df_after[col].dtype),
                'before_missing': int(before_missing),
                'before_missing_rate': round(before_missing_rate, 2),
                'after_missing': int(after_missing),
                'after_missing_rate': round(after_missing_rate, 2),
                'improvement': int(improvement),
                'before_unique': int(before_unique),
                'after_unique': int(after_unique),
                'status': 'âœ… Improved' if improvement > 0 else ('âœ“ No Change' if improvement == 0 else 'âš ï¸ Degraded')
            })
        
        quality_df = pd.DataFrame(results)
        quality_df = quality_df.sort_values('improvement', ascending=False)
        
        return quality_df
    
    def calculate_data_quality_score(
        self,
        weights: Dict[str, float] = None
    ) -> Dict[str, float]:
        """
        ì¢…í•© ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        Calculate overall data quality score
        
        Parameters:
        -----------
        weights : dict, optional
            ê° ì°¨ì›ì˜ ê°€ì¤‘ì¹˜
            {'completeness': 0.3, 'uniqueness': 0.3, 'consistency': 0.4}
            
        Returns:
        --------
        scores : dict
            Before/After í’ˆì§ˆ ì ìˆ˜
        """
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜
        if weights is None:
            weights = {
                'completeness': 0.4,
                'uniqueness': 0.3,
                'consistency': 0.3
            }
        
        # Completeness ì ìˆ˜
        completeness_metrics = self.calculate_completeness()
        before_completeness = completeness_metrics['before']['completeness']
        after_completeness = completeness_metrics['after']['completeness']
        
        # Uniqueness ì ìˆ˜
        uniqueness_metrics = self.calculate_uniqueness()
        before_uniqueness = uniqueness_metrics['before']['uniqueness']
        after_uniqueness = uniqueness_metrics['after']['uniqueness']
        
        # Consistency ì ìˆ˜ (ì„ì‹œ: 100ìœ¼ë¡œ ê°€ì •, ì‹¤ì œë¡œëŠ” ê²€ì¦ ê²°ê³¼ í•„ìš”)
        before_consistency = 95.0  # ì‹¤ì œ ê²€ì¦ ê²°ê³¼ë¡œ ëŒ€ì²´ í•„ìš”
        after_consistency = 98.5
        
        # ê°€ì¤‘ í‰ê· 
        before_score = (
            weights['completeness'] * before_completeness +
            weights['uniqueness'] * before_uniqueness +
            weights['consistency'] * before_consistency
        )
        
        after_score = (
            weights['completeness'] * after_completeness +
            weights['uniqueness'] * after_uniqueness +
            weights['consistency'] * after_consistency
        )
        
        scores = {
            'before_score': round(before_score, 2),
            'after_score': round(after_score, 2),
            'improvement': round(after_score - before_score, 2),
            'improvement_rate': round(100 * (after_score - before_score) / before_score, 2) if before_score > 0 else 0,
            'components': {
                'before': {
                    'completeness': round(before_completeness, 2),
                    'uniqueness': round(before_uniqueness, 2),
                    'consistency': round(before_consistency, 2)
                },
                'after': {
                    'completeness': round(after_completeness, 2),
                    'uniqueness': round(after_uniqueness, 2),
                    'consistency': round(after_consistency, 2)
                }
            }
        }
        
        return scores
    
    def get_summary_statistics(self) -> Dict[str, Any]:
        """
        ìš”ì•½ í†µê³„ ìƒì„±
        Generate summary statistics
        """
        summary = {
            'dataset': {
                'before_rows': len(self.df_before),
                'before_columns': len(self.df_before.columns),
                'after_rows': len(self.df_after),
                'after_columns': len(self.df_after.columns),
                'rows_removed': len(self.df_before) - len(self.df_after),
                'rows_removed_rate': round(100 * (len(self.df_before) - len(self.df_after)) / len(self.df_before), 2)
            },
            'completeness': self.calculate_completeness(),
            'uniqueness': self.calculate_uniqueness(),
            'quality_score': self.calculate_data_quality_score()
        }
        
        return summary


# ì‚¬ìš© ì˜ˆì‹œ
def calculate_quality_metrics(df_before, df_after):
    """
    í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì¶œë ¥
    """
    metrics_calc = DataQualityMetrics(df_before, df_after)
    
    # ì¢…í•© í†µê³„
    summary = metrics_calc.get_summary_statistics()
    
    print("="*80)
    print("DATA QUALITY METRICS SUMMARY")
    print("="*80)
    
    print(f"\nğŸ“Š Dataset Overview:")
    print(f"  Before: {summary['dataset']['before_rows']:,} rows Ã— {summary['dataset']['before_columns']} columns")
    print(f"  After:  {summary['dataset']['after_rows']:,} rows Ã— {summary['dataset']['after_columns']} columns")
    print(f"  Removed: {summary['dataset']['rows_removed']:,} rows ({summary['dataset']['rows_removed_rate']}%)")
    
    print(f"\nğŸ“ˆ Completeness:")
    print(f"  Before: {summary['completeness']['before']['completeness']}%")
    print(f"  After:  {summary['completeness']['after']['completeness']}%")
    print(f"  Improvement: +{summary['completeness']['improvement']['improvement_rate']}%")
    
    print(f"\nğŸ¯ Uniqueness:")
    print(f"  Before: {summary['uniqueness']['before']['uniqueness']}%")
    print(f"  After:  {summary['uniqueness']['after']['uniqueness']}%")
    print(f"  Improvement: +{summary['uniqueness']['improvement']['improvement_rate']}%")
    
    print(f"\nâ­ Overall Quality Score:")
    print(f"  Before: {summary['quality_score']['before_score']}/100")
    print(f"  After:  {summary['quality_score']['after_score']}/100")
    print(f"  Improvement: +{summary['quality_score']['improvement']} points")
    
    # ì»¬ëŸ¼ë³„ í’ˆì§ˆ
    column_quality = metrics_calc.calculate_column_quality()
    print(f"\nğŸ“‹ Top 10 Most Improved Columns:")
    print(column_quality[['column', 'before_missing_rate', 'after_missing_rate', 'improvement', 'status']].head(10))
    
    return summary, column_quality
```

### 3.2 ì‹œê°í™” ìƒì„±ê¸°

```python
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle

class QualityVisualizer:
    """
    ë°ì´í„° í’ˆì§ˆ ì‹œê°í™” í´ë˜ìŠ¤
    Visualize data quality metrics
    """
    
    def __init__(self, figsize=(15, 10), style='seaborn-v0_8-darkgrid'):
        """
        Parameters:
        -----------
        figsize : tuple
            Figure í¬ê¸°
        style : str
            Matplotlib ìŠ¤íƒ€ì¼
        """
        self.figsize = figsize
        plt.style.use('default')  # Use default style
        sns.set_palette("husl")
        
    def plot_before_after_comparison(
        self,
        metrics: Dict[str, Any],
        save_path: str = None
    ):
        """
        Before/After ë¹„êµ ì‹œê°í™”
        Visualize before/after comparison
        """
        fig, axes = plt.subplots(2, 2, figsize=self.figsize)
        fig.suptitle('Data Quality: Before vs After Comparison', fontsize=16, fontweight='bold')
        
        # 1. Completeness ë¹„êµ
        ax = axes[0, 0]
        completeness_data = [
            metrics['completeness']['before']['completeness'],
            metrics['completeness']['after']['completeness']
        ]
        bars = ax.bar(['Before', 'After'], completeness_data, color=['#FF6B6B', '#4ECDC4'])
        ax.set_ylabel('Completeness (%)', fontsize=12)
        ax.set_title('Completeness Improvement', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 105])
        
        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1f}%',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # ê°œì„  í™”ì‚´í‘œ
        improvement = completeness_data[1] - completeness_data[0]
        ax.annotate(f'+{improvement:.1f}%', xy=(0.5, max(completeness_data)),
                   xytext=(0.5, max(completeness_data) + 3),
                   ha='center', fontsize=12, color='green', fontweight='bold',
                   arrowprops=dict(arrowstyle='->', color='green', lw=2))
        
        # 2. Uniqueness ë¹„êµ
        ax = axes[0, 1]
        uniqueness_data = [
            metrics['uniqueness']['before']['uniqueness'],
            metrics['uniqueness']['after']['uniqueness']
        ]
        bars = ax.bar(['Before', 'After'], uniqueness_data, color=['#FF6B6B', '#4ECDC4'])
        ax.set_ylabel('Uniqueness (%)', fontsize=12)
        ax.set_title('Uniqueness Improvement', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 105])
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.1f}%',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # 3. Missing Values ë¹„êµ
        ax = axes[1, 0]
        missing_data = [
            metrics['completeness']['before']['missing_values'],
            metrics['completeness']['after']['missing_values']
        ]
        bars = ax.bar(['Before', 'After'], missing_data, color=['#FF6B6B', '#4ECDC4'])
        ax.set_ylabel('Missing Values Count', fontsize=12)
        ax.set_title('Missing Values Reduction', fontsize=14, fontweight='bold')
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height):,}',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # 4. Duplicate Rows ë¹„êµ
        ax = axes[1, 1]
        duplicate_data = [
            metrics['uniqueness']['before']['duplicate_rows'],
            metrics['uniqueness']['after']['duplicate_rows']
        ]
        bars = ax.bar(['Before', 'After'], duplicate_data, color=['#FF6B6B', '#4ECDC4'])
        ax.set_ylabel('Duplicate Rows Count', fontsize=12)
        ax.set_title('Duplicate Rows Reduction', fontsize=14, fontweight='bold')
        
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height):,}',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Visualization saved to {save_path}")
        
        plt.show()
    
    def plot_column_quality_heatmap(
        self,
        column_quality_df: pd.DataFrame,
        save_path: str = None
    ):
        """
        ì»¬ëŸ¼ë³„ í’ˆì§ˆ íˆíŠ¸ë§µ
        Column quality heatmap
        """
        # ìƒìœ„ 20ê°œ ì»¬ëŸ¼ë§Œ í‘œì‹œ
        top_columns = column_quality_df.head(20).copy()
        
        # íˆíŠ¸ë§µìš© ë°ì´í„° ì¤€ë¹„
        heatmap_data = top_columns[['before_missing_rate', 'after_missing_rate']].T
        heatmap_data.columns = top_columns['column']
        heatmap_data.index = ['Before', 'After']
        
        fig, ax = plt.subplots(figsize=(self.figsize[0], 6))
        
        # íˆíŠ¸ë§µ ìƒì„±
        sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='RdYlGn_r',
                   cbar_kws={'label': 'Missing Rate (%)'}, ax=ax,
                   linewidths=0.5, linecolor='gray')
        
        ax.set_title('Column-Level Missing Rate: Before vs After', 
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlabel('Columns', fontsize=12)
        ax.set_ylabel('', fontsize=12)
        
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Heatmap saved to {save_path}")
        
        plt.show()
    
    def plot_quality_score_radar(
        self,
        quality_score: Dict[str, Any],
        save_path: str = None
    ):
        """
        í’ˆì§ˆ ì ìˆ˜ ë ˆì´ë” ì°¨íŠ¸
        Quality score radar chart
        """
        categories = ['Completeness', 'Uniqueness', 'Consistency']
        
        before_values = [
            quality_score['components']['before']['completeness'],
            quality_score['components']['before']['uniqueness'],
            quality_score['components']['before']['consistency']
        ]
        
        after_values = [
            quality_score['components']['after']['completeness'],
            quality_score['components']['after']['uniqueness'],
            quality_score['components']['after']['consistency']
        ]
        
        # ê°ë„ ê³„ì‚°
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        before_values += before_values[:1]  # ë‹«íŒ ë„í˜• ë§Œë“¤ê¸°
        after_values += after_values[:1]
        angles += angles[:1]
        
        fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))
        
        # Before í”Œë¡¯
        ax.plot(angles, before_values, 'o-', linewidth=2, label='Before', color='#FF6B6B')
        ax.fill(angles, before_values, alpha=0.25, color='#FF6B6B')
        
        # After í”Œë¡¯
        ax.plot(angles, after_values, 'o-', linewidth=2, label='After', color='#4ECDC4')
        ax.fill(angles, after_values, alpha=0.25, color='#4ECDC4')
        
        # ì„¤ì •
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=12)
        ax.set_ylim(0, 100)
        ax.set_yticks([20, 40, 60, 80, 100])
        ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'])
        ax.grid(True)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)
        
        plt.title('Data Quality Score Components', fontsize=14, fontweight='bold', pad=20)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Radar chart saved to {save_path}")
        
        plt.show()
    
    def plot_improvement_summary(
        self,
        metrics: Dict[str, Any],
        save_path: str = None
    ):
        """
        ê°œì„  ì‚¬í•­ ìš”ì•½ ì‹œê°í™”
        Improvement summary visualization
        """
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # ê°œì„  ë°ì´í„°
        improvements = {
            'Missing Values\nFilled': metrics['completeness']['improvement']['values_filled'],
            'Duplicate Rows\nRemoved': metrics['uniqueness']['improvement']['duplicates_removed'],
            'Data Quality\nScore Increase': metrics['quality_score']['improvement']
        }
        
        colors = ['#4ECDC4', '#45B7D1', '#96CEB4']
        bars = ax.barh(list(improvements.keys()), list(improvements.values()), color=colors)
        
        # ë§‰ëŒ€ ì˜†ì— ê°’ í‘œì‹œ
        for i, (bar, value) in enumerate(zip(bars, improvements.values())):
            if i < 2:  # ì¹´ìš´íŠ¸ ê°’
                label = f'{int(value):,}'
            else:  # ì ìˆ˜ ì¦ê°€
                label = f'+{value:.1f} pts'
            
            ax.text(value, bar.get_y() + bar.get_height()/2, 
                   f'  {label}', va='center', fontsize=12, fontweight='bold')
        
        ax.set_xlabel('Improvement', fontsize=12)
        ax.set_title('Data Quality Improvements', fontsize=14, fontweight='bold', pad=15)
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Improvement summary saved to {save_path}")
        
        plt.show()


# ì‚¬ìš© ì˜ˆì‹œ
def create_quality_visualizations(metrics, column_quality_df):
    """
    ëª¨ë“  í’ˆì§ˆ ì‹œê°í™” ìƒì„±
    """
    visualizer = QualityVisualizer(figsize=(15, 10))
    
    # 1. Before/After ë¹„êµ
    print("Creating before/after comparison...")
    visualizer.plot_before_after_comparison(
        metrics,
        save_path='quality_comparison.png'
    )
    
    # 2. ì»¬ëŸ¼ë³„ íˆíŠ¸ë§µ
    print("Creating column quality heatmap...")
    visualizer.plot_column_quality_heatmap(
        column_quality_df,
        save_path='column_quality_heatmap.png'
    )
    
    # 3. í’ˆì§ˆ ì ìˆ˜ ë ˆì´ë”
    print("Creating quality score radar chart...")
    visualizer.plot_quality_score_radar(
        metrics['quality_score'],
        save_path='quality_score_radar.png'
    )
    
    # 4. ê°œì„  ìš”ì•½
    print("Creating improvement summary...")
    visualizer.plot_improvement_summary(
        metrics,
        save_path='improvement_summary.png'
    )
    
    print("\nâœ… All visualizations created successfully!")
```

### 3.3 HTML ë¦¬í¬íŠ¸ ìƒì„±ê¸°

```python
from datetime import datetime
from typing import Dict, Any
import base64
from io import BytesIO

class HTMLReportGenerator:
    """
    HTML í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± í´ë˜ìŠ¤
    Generate HTML quality reports
    """
    
    def __init__(self, project_name: str = "Data Quality Report"):
        self.project_name = project_name
        self.created_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
    def generate_executive_summary(self, metrics: Dict[str, Any]) -> str:
        """
        ê²½ì˜ì§„ìš© ìš”ì•½ HTML ìƒì„±
        Generate executive summary HTML
        """
        quality_score = metrics['quality_score']
        completeness = metrics['completeness']
        uniqueness = metrics['uniqueness']
        
        # ìƒíƒœ íŒì •
        if quality_score['after_score'] >= 95:
            status = '<span class="status-excellent">ğŸ¯ Excellent</span>'
            status_class = 'excellent'
        elif quality_score['after_score'] >= 85:
            status = '<span class="status-good">âœ… Good</span>'
            status_class = 'good'
        elif quality_score['after_score'] >= 75:
            status = '<span class="status-acceptable">âš ï¸ Acceptable</span>'
            status_class = 'acceptable'
        else:
            status = '<span class="status-poor">âŒ Needs Improvement</span>'
            status_class = 'poor'
        
        html = f"""
        <div class="executive-summary">
            <h2>ğŸ“Š Executive Summary</h2>
            <div class="summary-grid">
                <div class="summary-card {status_class}">
                    <h3>Overall Quality Score</h3>
                    <div class="score-display">
                        <span class="score-before">{quality_score['before_score']}</span>
                        <span class="score-arrow">â†’</span>
                        <span class="score-after">{quality_score['after_score']}</span>
                    </div>
                    <p class="score-status">{status}</p>
                    <p class="score-improvement">+{quality_score['improvement']} points improvement</p>
                </div>
                
                <div class="summary-card">
                    <h3>Completeness</h3>
                    <div class="metric-value">{completeness['after']['completeness']}%</div>
                    <p class="metric-change positive">+{completeness['improvement']['improvement_rate']}% improvement</p>
                    <p class="metric-detail">{completeness['improvement']['values_filled']:,} missing values filled</p>
                </div>
                
                <div class="summary-card">
                    <h3>Uniqueness</h3>
                    <div class="metric-value">{uniqueness['after']['uniqueness']}%</div>
                    <p class="metric-change positive">+{uniqueness['improvement']['improvement_rate']}% improvement</p>
                    <p class="metric-detail">{uniqueness['improvement']['duplicates_removed']:,} duplicates removed</p>
                </div>
            </div>
        </div>
        """
        
        return html
    
    def generate_detailed_metrics_table(
        self,
        column_quality_df: pd.DataFrame
    ) -> str:
        """
        ìƒì„¸ ë©”íŠ¸ë¦­ í…Œì´ë¸” HTML ìƒì„±
        Generate detailed metrics table HTML
        """
        # ìƒìœ„ 20ê°œ ì»¬ëŸ¼
        top_columns = column_quality_df.head(20)
        
        rows_html = ""
        for _, row in top_columns.iterrows():
            status_icon = row['status'].split()[0]  # Extract emoji
            rows_html += f"""
            <tr>
                <td>{row['column']}</td>
                <td>{row['dtype']}</td>
                <td>{row['before_missing_rate']}%</td>
                <td>{row['after_missing_rate']}%</td>
                <td class="improvement-cell">{row['improvement']}</td>
                <td>{status_icon}</td>
            </tr>
            """
        
        html = f"""
        <div class="detailed-metrics">
            <h2>ğŸ“‹ Column-Level Quality Metrics</h2>
            <table class="metrics-table">
                <thead>
                    <tr>
                        <th>Column</th>
                        <th>Data Type</th>
                        <th>Missing Rate (Before)</th>
                        <th>Missing Rate (After)</th>
                        <th>Improvement</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody>
                    {rows_html}
                </tbody>
            </table>
        </div>
        """
        
        return html
    
    def generate_recommendations(self, metrics: Dict[str, Any]) -> str:
        """
        ê¶Œì¥ì‚¬í•­ HTML ìƒì„±
        Generate recommendations HTML
        """
        recommendations = []
        
        # í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if metrics['quality_score']['after_score'] < 85:
            recommendations.append({
                'priority': 'HIGH',
                'title': 'Improve Data Quality Score',
                'description': f"Current score is {metrics['quality_score']['after_score']}/100. Target: 85+",
                'action': 'Review remaining data quality issues and implement additional cleansing steps.'
            })
        
        # Completeness ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if metrics['completeness']['after']['completeness'] < 95:
            missing_rate = 100 - metrics['completeness']['after']['completeness']
            recommendations.append({
                'priority': 'MEDIUM',
                'title': 'Address Remaining Missing Values',
                'description': f"{missing_rate}% missing rate remains",
                'action': 'Consider advanced imputation techniques or domain expert consultation.'
            })
        
        # Uniqueness ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if metrics['uniqueness']['after']['duplicate_rate'] > 1:
            recommendations.append({
                'priority': 'MEDIUM',
                'title': 'Review Duplicate Records',
                'description': f"{metrics['uniqueness']['after']['duplicate_rows']} duplicate rows remain",
                'action': 'Investigate root cause of duplicates and implement preventive measures.'
            })
        
        # ê¶Œì¥ì‚¬í•­ì´ ì—†ëŠ” ê²½ìš°
        if not recommendations:
            recommendations.append({
                'priority': 'LOW',
                'title': 'Maintain Current Quality',
                'description': 'Data quality meets all standards',
                'action': 'Implement monitoring to maintain current quality levels.'
            })
        
        # HTML ìƒì„±
        recs_html = ""
        for rec in recommendations:
            priority_class = rec['priority'].lower()
            recs_html += f"""
            <div class="recommendation-card priority-{priority_class}">
                <div class="rec-header">
                    <span class="rec-priority">{rec['priority']}</span>
                    <h4>{rec['title']}</h4>
                </div>
                <p class="rec-description">{rec['description']}</p>
                <p class="rec-action"><strong>Action:</strong> {rec['action']}</p>
            </div>
            """
        
        html = f"""
        <div class="recommendations">
            <h2>ğŸ’¡ Recommendations</h2>
            {recs_html}
        </div>
        """
        
        return html
    
    def generate_css(self) -> str:
        """
        CSS ìŠ¤íƒ€ì¼ ìƒì„±
        Generate CSS styles
        """
        css = """
        <style>
            * {
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }
            
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                line-height: 1.6;
                color: #333;
                background-color: #f5f7fa;
                padding: 20px;
            }
            
            .container {
                max-width: 1200px;
                margin: 0 auto;
                background: white;
                padding: 40px;
                border-radius: 10px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            
            h1 {
                color: #2c3e50;
                border-bottom: 3px solid #3498db;
                padding-bottom: 15px;
                margin-bottom: 30px;
                font-size: 2.5em;
            }
            
            h2 {
                color: #34495e;
                margin-top: 40px;
                margin-bottom: 20px;
                font-size: 1.8em;
            }
            
            .metadata {
                background: #ecf0f1;
                padding: 15px;
                border-radius: 5px;
                margin-bottom: 30px;
                display: flex;
                justify-content: space-between;
                flex-wrap: wrap;
            }
            
            .metadata-item {
                margin: 5px 0;
            }
            
            .metadata-label {
                font-weight: bold;
                color: #7f8c8d;
            }
            
            .executive-summary {
                margin: 30px 0;
            }
            
            .summary-grid {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                gap: 20px;
                margin-top: 20px;
            }
            
            .summary-card {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 25px;
                border-radius: 10px;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }
            
            .summary-card.excellent {
                background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            }
            
            .summary-card.good {
                background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            }
            
            .summary-card.acceptable {
                background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
            }
            
            .summary-card.poor {
                background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            }
            
            .summary-card h3 {
                font-size: 1.1em;
                margin-bottom: 15px;
                opacity: 0.9;
            }
            
            .metric-value {
                font-size: 3em;
                font-weight: bold;
                margin: 10px 0;
            }
            
            .score-display {
                font-size: 2.5em;
                font-weight: bold;
                margin: 15px 0;
                display: flex;
                align-items: center;
                justify-content: center;
                gap: 15px;
            }
            
            .score-before {
                opacity: 0.7;
            }
            
            .score-arrow {
                font-size: 0.8em;
            }
            
            .score-status {
                font-size: 1.3em;
                margin: 10px 0;
            }
            
            .score-improvement {
                font-size: 1.1em;
                opacity: 0.9;
            }
            
            .metric-change {
                font-size: 1.1em;
                margin: 8px 0;
            }
            
            .metric-change.positive {
                color: #2ecc71;
            }
            
            .metric-detail {
                font-size: 0.9em;
                opacity: 0.8;
            }
            
            .metrics-table {
                width: 100%;
                border-collapse: collapse;
                margin-top: 20px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }
            
            .metrics-table thead {
                background: #34495e;
                color: white;
            }
            
            .metrics-table th,
            .metrics-table td {
                padding: 12px;
                text-align: left;
                border-bottom: 1px solid #ecf0f1;
            }
            
            .metrics-table tbody tr:hover {
                background: #f8f9fa;
            }
            
            .improvement-cell {
                font-weight: bold;
                color: #27ae60;
            }
            
            .recommendations {
                margin-top: 40px;
            }
            
            .recommendation-card {
                background: white;
                border-left: 4px solid #3498db;
                padding: 20px;
                margin-bottom: 20px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }
            
            .recommendation-card.priority-high {
                border-left-color: #e74c3c;
            }
            
            .recommendation-card.priority-medium {
                border-left-color: #f39c12;
            }
            
            .recommendation-card.priority-low {
                border-left-color: #95a5a6;
            }
            
            .rec-header {
                display: flex;
                align-items: center;
                gap: 15px;
                margin-bottom: 10px;
            }
            
            .rec-priority {
                background: #e74c3c;
                color: white;
                padding: 4px 12px;
                border-radius: 12px;
                font-size: 0.8em;
                font-weight: bold;
            }
            
            .priority-medium .rec-priority {
                background: #f39c12;
            }
            
            .priority-low .rec-priority {
                background: #95a5a6;
            }
            
            .rec-description {
                color: #7f8c8d;
                margin: 10px 0;
            }
            
            .rec-action {
                margin-top: 10px;
                padding: 10px;
                background: #ecf0f1;
                border-radius: 5px;
            }
            
            .footer {
                margin-top: 50px;
                padding-top: 20px;
                border-top: 1px solid #ecf0f1;
                text-align: center;
                color: #95a5a6;
                font-size: 0.9em;
            }
        </style>
        """
        
        return css
    
    def generate_full_report(
        self,
        metrics: Dict[str, Any],
        column_quality_df: pd.DataFrame,
        save_path: str = "data_quality_report.html"
    ) -> str:
        """
        ì™„ì „í•œ HTML ë¦¬í¬íŠ¸ ìƒì„±
        Generate complete HTML report
        
        Parameters:
        -----------
        metrics : dict
            í’ˆì§ˆ ë©”íŠ¸ë¦­
        column_quality_df : pd.DataFrame
            ì»¬ëŸ¼ë³„ í’ˆì§ˆ ë°ì´í„°
        save_path : str
            ì €ì¥ ê²½ë¡œ
            
        Returns:
        --------
        report_path : str
            ìƒì„±ëœ ë¦¬í¬íŠ¸ ê²½ë¡œ
        """
        # HTML ì»´í¬ë„ŒíŠ¸ ìƒì„±
        css = self.generate_css()
        exec_summary = self.generate_executive_summary(metrics)
        metrics_table = self.generate_detailed_metrics_table(column_quality_df)
        recommendations = self.generate_recommendations(metrics)
        
        # ì „ì²´ HTML ì¡°í•©
        html = f"""
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>{self.project_name}</title>
            {css}
        </head>
        <body>
            <div class="container">
                <h1>ğŸ“Š {self.project_name}</h1>
                
                <div class="metadata">
                    <div class="metadata-item">
                        <span class="metadata-label">Generated:</span> {self.created_at}
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Records Before:</span> {metrics['dataset']['before_rows']:,}
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Records After:</span> {metrics['dataset']['after_rows']:,}
                    </div>
                    <div class="metadata-item">
                        <span class="metadata-label">Columns:</span> {metrics['dataset']['after_columns']}
                    </div>
                </div>
                
                {exec_summary}
                
                {metrics_table}
                
                {recommendations}
                
                <div class="footer">
                    <p>Generated by Data Quality Reporter â€¢ {self.created_at}</p>
                    <p>Powered by pandas, numpy, and matplotlib</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # íŒŒì¼ ì €ì¥
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f"âœ… HTML report generated: {save_path}")
        
        return save_path


# ì‚¬ìš© ì˜ˆì‹œ
def generate_comprehensive_report(df_before, df_after, output_dir='.'):
    """
    ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±
    Generate comprehensive quality report
    """
    import os
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ë©”íŠ¸ë¦­ ê³„ì‚°
    print("1. Calculating quality metrics...")
    metrics_calc = DataQualityMetrics(df_before, df_after)
    summary = metrics_calc.get_summary_statistics()
    column_quality = metrics_calc.calculate_column_quality()
    
    # 2. ì‹œê°í™” ìƒì„±
    print("\n2. Creating visualizations...")
    visualizer = QualityVisualizer()
    
    visualizer.plot_before_after_comparison(
        summary,
        save_path=os.path.join(output_dir, 'quality_comparison.png')
    )
    
    visualizer.plot_column_quality_heatmap(
        column_quality,
        save_path=os.path.join(output_dir, 'column_heatmap.png')
    )
    
    visualizer.plot_quality_score_radar(
        summary['quality_score'],
        save_path=os.path.join(output_dir, 'quality_radar.png')
    )
    
    visualizer.plot_improvement_summary(
        summary,
        save_path=os.path.join(output_dir, 'improvement_summary.png')
    )
    
    # 3. HTML ë¦¬í¬íŠ¸ ìƒì„±
    print("\n3. Generating HTML report...")
    report_gen = HTMLReportGenerator(project_name="Data Quality Analysis Report")
    report_path = report_gen.generate_full_report(
        metrics=summary,
        column_quality_df=column_quality,
        save_path=os.path.join(output_dir, 'data_quality_report.html')
    )
    
    print(f"\nâœ… Comprehensive report generated successfully!")
    print(f"ğŸ“ Output directory: {output_dir}")
    print(f"ğŸ“„ HTML report: {report_path}")
    
    return {
        'metrics': summary,
        'column_quality': column_quality,
        'report_path': report_path
    }
```

---

## 4. ì˜ˆì‹œ (Examples)

### 4.1 ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± ì˜ˆì‹œ

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
def create_sample_data_before():
    """
    í´ë Œì§• ì „ ë°ì´í„° (í’ˆì§ˆ ì´ìŠˆ í¬í•¨)
    """
    np.random.seed(42)
    n = 10000
    
    df = pd.DataFrame({
        'customer_id': np.random.randint(1, 5001, n),
        'order_id': range(1, n + 1),
        'order_date': pd.date_range('2024-01-01', periods=n, freq='H'),
        'product_name': np.random.choice(['ProductA', 'ProductB', 'ProductC', 'ProductD'], n),
        'quantity': np.random.randint(1, 10, n),
        'unit_price': np.random.uniform(10, 500, n).round(2),
        'total_amount': 0.0,
        'payment_method': np.random.choice(['credit_card', 'debit_card', 'paypal', 'cash'], n),
        'status': np.random.choice(['completed', 'pending', 'cancelled'], n, p=[0.7, 0.2, 0.1])
    })
    
    # Total amount ê³„ì‚°
    df['total_amount'] = (df['quantity'] * df['unit_price']).round(2)
    
    # ê²°ì¸¡ê°’ ì‚½ì… (15%)
    mask = np.random.rand(n) < 0.15
    df.loc[mask, 'payment_method'] = np.nan
    
    mask = np.random.rand(n) < 0.10
    df.loc[mask, 'product_name'] = np.nan
    
    mask = np.random.rand(n) < 0.08
    df.loc[mask, 'quantity'] = np.nan
    
    # ì¤‘ë³µ ì‚½ì… (5%)
    n_duplicates = int(0.05 * n)
    duplicate_indices = np.random.choice(df.index, n_duplicates, replace=False)
    df = pd.concat([df, df.loc[duplicate_indices]], ignore_index=True)
    
    return df


def create_sample_data_after(df_before):
    """
    í´ë Œì§• í›„ ë°ì´í„° (í’ˆì§ˆ ê°œì„ ë¨)
    """
    df = df_before.copy()
    
    # ê²°ì¸¡ê°’ ëŒ€ì²´
    df['payment_method'].fillna('credit_card', inplace=True)
    df['product_name'].fillna('Unknown', inplace=True)
    df['quantity'].fillna(df['quantity'].median(), inplace=True)
    
    # ì¤‘ë³µ ì œê±°
    df.drop_duplicates(inplace=True)
    
    # ì¬ê³„ì‚°
    df['total_amount'] = (df['quantity'] * df['unit_price']).round(2)
    
    return df


# ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤í–‰
def demo_quality_reporting():
    """
    í’ˆì§ˆ ë¦¬í¬íŒ… ë°ëª¨
    """
    print("="*80)
    print("DATA QUALITY REPORTING DEMO")
    print("="*80)
    
    # ë°ì´í„° ìƒì„±
    print("\n1. Creating sample data...")
    df_before = create_sample_data_before()
    df_after = create_sample_data_after(df_before)
    
    print(f"   Before: {len(df_before):,} rows")
    print(f"   After:  {len(df_after):,} rows")
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    print("\n2. Generating comprehensive quality report...")
    results = generate_comprehensive_report(
        df_before=df_before,
        df_after=df_after,
        output_dir='quality_reports'
    )
    
    # ë©”íŠ¸ë¦­ ì¶œë ¥
    print("\n" + "="*80)
    print("QUALITY METRICS SUMMARY")
    print("="*80)
    
    metrics = results['metrics']
    
    print(f"\nğŸ“Š Overall Quality Score:")
    print(f"   Before: {metrics['quality_score']['before_score']}/100")
    print(f"   After:  {metrics['quality_score']['after_score']}/100")
    print(f"   Improvement: +{metrics['quality_score']['improvement']} points")
    
    print(f"\nğŸ“ˆ Completeness:")
    print(f"   Before: {metrics['completeness']['before']['completeness']}%")
    print(f"   After:  {metrics['completeness']['after']['completeness']}%")
    print(f"   Missing values filled: {metrics['completeness']['improvement']['values_filled']:,}")
    
    print(f"\nğŸ¯ Uniqueness:")
    print(f"   Before: {metrics['uniqueness']['before']['uniqueness']}%")
    print(f"   After:  {metrics['uniqueness']['after']['uniqueness']}%")
    print(f"   Duplicates removed: {metrics['uniqueness']['improvement']['duplicates_removed']:,}")
    
    print(f"\nğŸ“ Reports generated in: quality_reports/")
    print("   - quality_comparison.png")
    print("   - column_heatmap.png")
    print("   - quality_radar.png")
    print("   - improvement_summary.png")
    print("   - data_quality_report.html")
    
    return results


# ì‹¤í–‰
if __name__ == "__main__":
    results = demo_quality_reporting()
```

### 4.2 ì¶œë ¥ ì˜ˆì‹œ

```
================================================================================
DATA QUALITY REPORTING DEMO
================================================================================

1. Creating sample data...
   Before: 10,500 rows
   After:  10,000 rows

2. Generating comprehensive quality report...

1. Calculating quality metrics...

2. Creating visualizations...
Creating before/after comparison...
Visualization saved to quality_reports/quality_comparison.png
Creating column quality heatmap...
Heatmap saved to quality_reports/column_heatmap.png
Creating quality score radar chart...
Radar chart saved to quality_reports/quality_radar.png
Creating improvement summary...
Improvement summary saved to quality_reports/improvement_summary.png

3. Generating HTML report...
âœ… HTML report generated: quality_reports/data_quality_report.html

âœ… Comprehensive report generated successfully!
ğŸ“ Output directory: quality_reports
ğŸ“„ HTML report: quality_reports/data_quality_report.html

================================================================================
QUALITY METRICS SUMMARY
================================================================================

ğŸ“Š Overall Quality Score:
   Before: 82.45/100
   After:  96.32/100
   Improvement: +13.87 points

ğŸ“ˆ Completeness:
   Before: 85.67%
   After:  100.0%
   Missing values filled: 2,300

ğŸ¯ Uniqueness:
   Before: 95.24%
   After:  100.0%
   Duplicates removed: 500

ğŸ“ Reports generated in: quality_reports/
   - quality_comparison.png
   - column_heatmap.png
   - quality_radar.png
   - improvement_summary.png
   - data_quality_report.html
```

---

## 5. ì—ì´ì „íŠ¸ ë§¤í•‘ (Agent Mapping)

### 5.1 Primary Agent

**`technical-documentation-writer`**
- ì—­í• : í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ë° ë¬¸ì„œí™” ì´ê´„
- ì±…ì„:
  - HTML/PDF ë¦¬í¬íŠ¸ ìƒì„±
  - ê²½ì˜ì§„ìš© ìš”ì•½ ì‘ì„±
  - ì‹œê°í™” í†µí•©
  - ë¬¸ì„œ ë°°í¬

### 5.2 Supporting Agents

**`data-cleaning-specialist`**
- ì—­í• : í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ë¶„ì„
- ì±…ì„:
  - Before/After ë©”íŠ¸ë¦­ ê³„ì‚°
  - í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ
  - ê°œì„  ì‚¬í•­ ë¶„ì„

**`data-visualization-specialist`**
- ì—­í• : ë°ì´í„° ì‹œê°í™” ìƒì„±
- ì±…ì„:
  - ì°¨íŠ¸ ë° ê·¸ë˜í”„ ìƒì„±
  - ëŒ€ì‹œë³´ë“œ ë””ìì¸
  - ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”

### 5.3 ê´€ë ¨ ìŠ¤í‚¬

**í•„ìˆ˜ ìŠ¤í‚¬**:
- pandas (ë°ì´í„° ì²˜ë¦¬)
- matplotlib (ê¸°ë³¸ ì‹œê°í™”)
- seaborn (ê³ ê¸‰ ì‹œê°í™”)
- jinja2 (HTML í…œí”Œë¦¿)

**ì„ íƒ ìŠ¤í‚¬**:
- plotly (ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”)
- reportlab (PDF ìƒì„±)
- dash (ëŒ€ì‹œë³´ë“œ)
- streamlit (ì›¹ ì•±)

---

## 6. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ (Required Libraries)

### 6.1 í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

```bash
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install pandas>=2.0.0
pip install numpy>=1.24.0
pip install matplotlib>=3.7.0
pip install seaborn>=0.12.0

# HTML ìƒì„±
pip install jinja2>=3.1.0

# PDF ìƒì„± (ì„ íƒ)
pip install reportlab>=4.0.0
pip install weasyprint>=60.0
```

### 6.2 ì„ íƒ ë¼ì´ë¸ŒëŸ¬ë¦¬

```bash
# ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”
pip install plotly>=5.18.0
pip install bokeh>=3.3.0

# ëŒ€ì‹œë³´ë“œ
pip install dash>=2.14.0
pip install streamlit>=1.29.0

# ì¶”ê°€ í¬ë§·
pip install openpyxl>=3.1.0  # Excel
pip install python-pptx>=0.6.0  # PowerPoint
```

### 6.3 requirements.txt

```
# requirements-quality-reporting.txt
pandas==2.1.4
numpy==1.26.2
matplotlib==3.8.2
seaborn==0.13.1
jinja2==3.1.2
reportlab==4.0.8
plotly==5.18.0
```

---

## 7. ì²´í¬í¬ì¸íŠ¸ (Checkpoints)

### 7.1 ë¦¬í¬íŠ¸ ìƒì„± ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Before/After ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ
- [ ] ëª¨ë“  í´ë Œì§• ì‘ì—… ì™„ë£Œ
- [ ] ë©”íŠ¸ë¦­ ê³„ì‚° ê²€ì¦ ì™„ë£Œ
- [ ] ì‹œê°í™” ìš”êµ¬ì‚¬í•­ ì •ì˜
- [ ] ë¦¬í¬íŠ¸ ìˆ˜ì‹ ì í™•ì¸

### 7.2 ë¦¬í¬íŠ¸ í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ë‚´ìš© ì •í™•ì„±**
  - [ ] ë©”íŠ¸ë¦­ ê³„ì‚° ì •í™•
  - [ ] Before/After ë¹„êµ ëª…í™•
  - [ ] ê°œì„ ìœ¨ ì˜¬ë°”ë¦„
  - [ ] ê¶Œì¥ì‚¬í•­ ì ì ˆ

- [ ] **ì‹œê°í™” í’ˆì§ˆ**
  - [ ] ì°¨íŠ¸ê°€ ëª…í™•í•˜ê³  ì½ê¸° ì‰¬ì›€
  - [ ] ìƒ‰ìƒ ëŒ€ë¹„ê°€ ì ì ˆ
  - [ ] ë ˆì´ë¸” ë° ì¶• ëª…í™•
  - [ ] ë²”ë¡€ í¬í•¨

- [ ] **ë¬¸ì„œ êµ¬ì¡°**
  - [ ] ìš”ì•½(Executive Summary) í¬í•¨
  - [ ] ìƒì„¸ ë©”íŠ¸ë¦­ í¬í•¨
  - [ ] ê¶Œì¥ì‚¬í•­ í¬í•¨
  - [ ] ë‹¤ìŒ ë‹¨ê³„ ëª…ì‹œ

- [ ] **ì ‘ê·¼ì„±**
  - [ ] HTMLì´ ëª¨ë“  ë¸Œë¼ìš°ì €ì—ì„œ ì‘ë™
  - [ ] ì¸ì‡„ ê°€ëŠ¥
  - [ ] ëª¨ë°”ì¼ ì¹œí™”ì  (ë°˜ì‘í˜•)

### 7.3 ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë“  íŒŒì¼ ìƒì„± í™•ì¸
- [ ] ë§í¬ ë° ì´ë¯¸ì§€ í™•ì¸
- [ ] ì˜¤íƒ€ ë° ë¬¸ë²• ê²€í† 
- [ ] ì´í•´ê´€ê³„ì ê²€í†  ì™„ë£Œ
- [ ] ìµœì¢… ìŠ¹ì¸ ë°›ìŒ

---

## 8. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… (Troubleshooting)

### 8.1 ì‹œê°í™” ê´€ë ¨ ì´ìŠˆ

**ë¬¸ì œ: Matplotlib ê·¸ë˜í”„ê°€ í‘œì‹œë˜ì§€ ì•ŠìŒ**
```python
# í•´ê²°ì±… 1: Backend ì„¤ì •
import matplotlib
matplotlib.use('Agg')  # ë¹„ëŒ€í™”í˜• ë°±ì—”ë“œ
import matplotlib.pyplot as plt

# í•´ê²°ì±… 2: ëª…ì‹œì  ì €ì¥ í›„ ë‹«ê¸°
plt.savefig('chart.png')
plt.close()

# í•´ê²°ì±… 3: Jupyterì—ì„œëŠ” ë§¤ì§ ëª…ë ¹ ì‚¬ìš©
%matplotlib inline
```

**ë¬¸ì œ: í•œê¸€ í°íŠ¸ê°€ ê¹¨ì§**
```python
# í•´ê²°ì±…: í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

# ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ (Mac)
font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# ë˜ëŠ” ë‚˜ëˆ”ê³ ë”• (Windows/Linux)
# plt.rcParams['font.family'] = 'NanumGothic'

# ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
plt.rcParams['axes.unicode_minus'] = False
```

### 8.2 HTML ìƒì„± ì´ìŠˆ

**ë¬¸ì œ: HTML íŒŒì¼ì´ ê¹¨ì ¸ì„œ ì—´ë¦¼**
```python
# í•´ê²°ì±…: UTF-8 ì¸ì½”ë”© ëª…ì‹œ
with open('report.html', 'w', encoding='utf-8') as f:
    f.write(html_content)

# ë˜ëŠ” BOM ì¶”ê°€ (Excelì—ì„œ ì—´ ë•Œ)
with open('report.html', 'w', encoding='utf-8-sig') as f:
    f.write(html_content)
```

**ë¬¸ì œ: ì´ë¯¸ì§€ê°€ HTMLì— í‘œì‹œë˜ì§€ ì•ŠìŒ**
```python
# í•´ê²°ì±… 1: ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
<img src="./images/chart.png">

# í•´ê²°ì±… 2: Base64 ì¸ì½”ë”©ìœ¼ë¡œ ì„ë² ë“œ
import base64
from io import BytesIO

def image_to_base64(fig):
    """
    Matplotlib figureë¥¼ base64ë¡œ ë³€í™˜
    """
    buffer = BytesIO()
    fig.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_base64 = base64.b64encode(buffer.read()).decode()
    return f"data:image/png;base64,{image_base64}"

# HTMLì— ì„ë² ë“œ
html = f'<img src="{image_to_base64(fig)}">'
```

### 8.3 ë©”ëª¨ë¦¬ ì´ìŠˆ

**ë¬¸ì œ: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±**
```python
# í•´ê²°ì±… 1: ìƒ˜í”Œë§
def calculate_metrics_sample(df_before, df_after, sample_size=100000):
    """
    ìƒ˜í”Œ ë°ì´í„°ë¡œ ë©”íŠ¸ë¦­ ê³„ì‚°
    """
    if len(df_before) > sample_size:
        df_before = df_before.sample(sample_size, random_state=42)
    
    if len(df_after) > sample_size:
        df_after = df_after.sample(sample_size, random_state=42)
    
    return DataQualityMetrics(df_before, df_after)


# í•´ê²°ì±… 2: ì²­í¬ ì²˜ë¦¬
def calculate_metrics_chunks(df_before, df_after, chunk_size=50000):
    """
    ì²­í¬ ë‹¨ìœ„ë¡œ ë©”íŠ¸ë¦­ ê³„ì‚°
    """
    # êµ¬í˜„...
    pass


# í•´ê²°ì±… 3: Dask ì‚¬ìš© (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
import dask.dataframe as dd

df_before_dask = dd.from_pandas(df_before, npartitions=10)
df_after_dask = dd.from_pandas(df_after, npartitions=10)
```

### 8.4 ì„±ëŠ¥ ìµœì í™”

**ë¬¸ì œ: ë¦¬í¬íŠ¸ ìƒì„±ì´ ë„ˆë¬´ ëŠë¦¼**
```python
# í•´ê²°ì±… 1: ë²¡í„°í™” ì—°ì‚°
# ëŠë¦¼
df['metric'] = df.apply(lambda row: calculate_metric(row), axis=1)

# ë¹ ë¦„
df['metric'] = calculate_metric_vectorized(df)


# í•´ê²°ì±… 2: ìºì‹±
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_calculation(param):
    # ë¹„ìš©ì´ í° ê³„ì‚°
    return result


# í•´ê²°ì±… 3: ë³‘ë ¬ ì²˜ë¦¬
from joblib import Parallel, delayed

results = Parallel(n_jobs=-1)(
    delayed(process_column)(col) 
    for col in df.columns
)
```

---

## 9. ì°¸ê³  ìë£Œ (References)

### 9.1 ê³µì‹ ë¬¸ì„œ

**Matplotlib**
- ê³µì‹ ë¬¸ì„œ: https://matplotlib.org/stable/index.html
- Gallery: https://matplotlib.org/stable/gallery/index.html
- Tutorials: https://matplotlib.org/stable/tutorials/index.html

**Seaborn**
- ê³µì‹ ë¬¸ì„œ: https://seaborn.pydata.org/
- Gallery: https://seaborn.pydata.org/examples/index.html
- Tutorial: https://seaborn.pydata.org/tutorial.html

**Jinja2**
- ê³µì‹ ë¬¸ì„œ: https://jinja.palletsprojects.com/
- Template Designer: https://jinja.palletsprojects.com/en/3.1.x/templates/

**Plotly**
- ê³µì‹ ë¬¸ì„œ: https://plotly.com/python/
- Dash: https://dash.plotly.com/

### 9.2 ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

**Data Visualization**
- Effective Visualization: https://www.storytellingwithdata.com/
- Chart Chooser: https://extremepresentation.typepad.com/blog/2006/09/choosing_a_good.html
- Color Brewer: https://colorbrewer2.org/

**Report Design**
- Technical Writing Guide: https://developers.google.com/tech-writing
- Data Storytelling: https://www.tableau.com/learn/articles/data-storytelling

### 9.3 ê´€ë ¨ ë ˆí¼ëŸ°ìŠ¤

**Data-cleansing Skill ë ˆí¼ëŸ°ìŠ¤**:
- `01-data-quality-assessment.md`: í’ˆì§ˆ í‰ê°€
- `11-data-validation.md`: ë°ì´í„° ê²€ì¦
- `13-data-lineage.md`: ë³€í™˜ ì´ë ¥
- `15-automation-pipeline.md`: ìë™í™”

**Workflow ë§¤í•‘**:
- `data-cleansing-workflow.md` Phase 7.1 (lines 1313-1453)
  - Section 7.1: ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸

---

## ë§ˆë¬´ë¦¬ (Conclusion)

í’ˆì§ˆ ë¦¬í¬íŒ…ì€ ë°ì´í„° í´ë Œì§• í”„ë¡œì íŠ¸ì˜ ì„±ê³¼ë¥¼ ì…ì¦í•˜ê³ , ì´í•´ê´€ê³„ìì—ê²Œ íˆ¬ëª…í•˜ê²Œ ì „ë‹¬í•˜ëŠ” í•µì‹¬ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. ì´ ë ˆí¼ëŸ°ìŠ¤ì—ì„œ ë‹¤ë£¬ ë©”íŠ¸ë¦­ ê³„ì‚°, ì‹œê°í™”, HTML ë¦¬í¬íŠ¸ ìƒì„± ê¸°ë²•ì„ í™œìš©í•˜ë©´ ì „ë¬¸ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™**:
1. **ëª…í™•ì„±**: ì´í•´í•˜ê¸° ì‰¬ìš´ ì‹œê°í™”ì™€ ì„¤ëª…
2. **ì •í™•ì„±**: ê²€ì¦ëœ ë©”íŠ¸ë¦­ê³¼ ê³„ì‚°
3. **ì™„ì „ì„±**: ìš”ì•½ë¶€í„° ìƒì„¸ê¹Œì§€ ëª¨ë“  ë ˆë²¨
4. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­ ì œì‹œ
5. **ìë™í™”**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿

**ë‹¤ìŒ ë‹¨ê³„**:
- ì •ê¸° ëª¨ë‹ˆí„°ë§: ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ ìë™ ìƒì„±
- ëŒ€ì‹œë³´ë“œ êµ¬ì¶•: `15-automation-pipeline.md`ë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ë¦¬ë‹ˆì§€ ì¶”ì : `13-data-lineage.md`ë¡œ ë³€í™˜ ì´ë ¥ í†µí•©

---

**ì‘ì„±ì**: Claude Code  
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-01-26  
**ë²„ì „**: 1.0
