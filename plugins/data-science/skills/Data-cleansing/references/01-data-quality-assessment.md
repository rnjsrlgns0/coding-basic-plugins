# Data Quality Assessment (ë°ì´í„° í’ˆì§ˆ í‰ê°€)

**ìƒì„±ì¼**: 2025-01-25  
**ë²„ì „**: 1.0  
**ë‹´ë‹¹ ì—ì´ì „íŠ¸**: `data-cleaning-specialist`, `data-scientist`

---

## 1. ê°œìš”

### 1.1 ëª©ì 

ë°ì´í„° í’ˆì§ˆ í‰ê°€ëŠ” ë°ì´í„° í´ë Œì§• ì›Œí¬í”Œë¡œìš°ì˜ ì²« ë²ˆì§¸ì´ì ê°€ì¥ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. ì´ í”„ë¡œì„¸ìŠ¤ëŠ” ë°ì´í„°ë¥¼ ì²˜ìŒ ë°›ì•˜ì„ ë•Œ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” ì¢…í•©ì ì¸ í’ˆì§ˆ í‰ê°€ ë°©ë²•ë¡ ì„ ì œê³µí•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ëª©í‘œë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤:

- **í’ˆì§ˆ ì´ìŠˆ ì‹ë³„**: ê²°ì¸¡ê°’, ì¤‘ë³µ, ì´ìƒì¹˜, íƒ€ì… ë¶ˆì¼ì¹˜ ë“± ëª¨ë“  í’ˆì§ˆ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ íƒì§€
- **ìš°ì„ ìˆœìœ„ ê²°ì •**: ì‹ë³„ëœ ì´ìŠˆì˜ ì‹¬ê°ë„ë¥¼ í‰ê°€í•˜ê³  ì²˜ë¦¬ ìˆœì„œë¥¼ ê²°ì •
- **í´ë Œì§• ì „ëµ ìˆ˜ë¦½**: í’ˆì§ˆ í‰ê°€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ í´ë Œì§• ë°©ë²• ì„ íƒ
- **ë²¤ì¹˜ë§ˆí¬ ì„¤ì •**: í´ë Œì§• ì „í›„ ë¹„êµë¥¼ ìœ„í•œ ê¸°ì¤€ì„  í™•ë¦½

### 1.2 ì ìš© ì‹œê¸°

ë°ì´í„° í’ˆì§ˆ í‰ê°€ëŠ” ë‹¤ìŒ ìƒí™©ì—ì„œ ë°˜ë“œì‹œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:

1. **ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìˆ˜ë ¹ ì‹œ**: ì²˜ìŒ ë°›ì€ ë°ì´í„°ì˜ ì „ë°˜ì ì¸ ìƒíƒœ íŒŒì•…
2. **ë°ì´í„° ì†ŒìŠ¤ ë³€ê²½ ì‹œ**: ìƒˆë¡œìš´ ë°ì´í„° ì œê³µìë‚˜ ì‹œìŠ¤í…œìœ¼ë¡œë¶€í„° ë°ì´í„° ìˆ˜ì§‘
3. **ì •ê¸°ì  í’ˆì§ˆ ì ê²€**: ì£¼ê¸°ì ì¸ ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (ì˜ˆ: ì›”ë³„, ë¶„ê¸°ë³„)
4. **ì´ìƒ ì§•í›„ ë°œê²¬ ì‹œ**: ë¶„ì„ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ë•Œ ë°ì´í„° í’ˆì§ˆ ì¬ì ê²€
5. **í”„ë¡œì íŠ¸ ì‹œì‘ ì „**: ë°ì´í„° ë¶„ì„ ë˜ëŠ” ML ëª¨ë¸ë§ ì°©ìˆ˜ ì „ í•„ìˆ˜ ì ê²€

### 1.3 ì£¼ìš” êµ¬ì„± ìš”ì†Œ

ë°ì´í„° í’ˆì§ˆ í‰ê°€ëŠ” ì„¸ ê°€ì§€ í•µì‹¬ ì˜ì—­ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. **ë°ì´í„° í”„ë¡œíŒŒì¼ë§**: ê¸°ë³¸ í†µê³„, ë¶„í¬, íŒ¨í„´ ë¶„ì„
2. **ë°ì´í„° íƒ€ì… ê²€ì¦**: ìŠ¤í‚¤ë§ˆ ì¼ì¹˜ ì—¬ë¶€ ë° íƒ€ì… ë¬´ê²°ì„± í™•ì¸
3. **ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦**: ë„ë©”ì¸ë³„ ì œì•½ ì¡°ê±´ ë° ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦

---

## 2. ì´ë¡ ì  ë°°ê²½

### 2.1 ë°ì´í„° í’ˆì§ˆì˜ ì°¨ì›

ë°ì´í„° í’ˆì§ˆì€ ì—¬ëŸ¬ ì°¨ì›ì—ì„œ í‰ê°€ë©ë‹ˆë‹¤:

#### 2.1.1 ì™„ì „ì„± (Completeness)
- **ì •ì˜**: í•„ìˆ˜ ë°ì´í„°ê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì •ë„
- **ì¸¡ì •**: ê²°ì¸¡ê°’ ë¹„ìœ¨, í•„ìˆ˜ í•„ë“œ ëˆ„ë½ë¥ 
- **ì¤‘ìš”ì„±**: ë¶ˆì™„ì „í•œ ë°ì´í„°ëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ì™œê³¡ì‹œí‚¤ê³  ëª¨ë¸ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚´

#### 2.1.2 ì •í™•ì„± (Accuracy)
- **ì •ì˜**: ë°ì´í„°ê°€ ì‹¤ì œ ê°’ì„ ì˜¬ë°”ë¥´ê²Œ ë°˜ì˜í•˜ëŠ” ì •ë„
- **ì¸¡ì •**: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ìœ„ë°˜ë¥ , ê°’ ë²”ìœ„ ì´ˆê³¼ìœ¨
- **ì¤‘ìš”ì„±**: ë¶€ì •í™•í•œ ë°ì´í„°ëŠ” ì˜ëª»ëœ ì˜ì‚¬ê²°ì •ìœ¼ë¡œ ì´ì–´ì§

#### 2.1.3 ì¼ê´€ì„± (Consistency)
- **ì •ì˜**: ë™ì¼í•œ ì •ë³´ê°€ ì—¬ëŸ¬ ê³³ì—ì„œ ì¼ì¹˜í•˜ëŠ” ì •ë„
- **ì¸¡ì •**: êµì°¨ í•„ë“œ ë¶ˆì¼ì¹˜ìœ¨, ì¤‘ë³µ ë ˆì½”ë“œ ë¹„ìœ¨
- **ì¤‘ìš”ì„±**: ì¼ê´€ì„± ì—†ëŠ” ë°ì´í„°ëŠ” ì‹ ë¢°ì„±ì„ ë–¨ì–´ëœ¨ë¦¼

#### 2.1.4 ì ì‹œì„± (Timeliness)
- **ì •ì˜**: ë°ì´í„°ê°€ í˜„ì¬ ìƒí™©ì„ ë°˜ì˜í•˜ëŠ” ì •ë„
- **ì¸¡ì •**: ìµœê·¼ ì—…ë°ì´íŠ¸ ë‚ ì§œ, ë°ì´í„° ì§€ì—° ì‹œê°„
- **ì¤‘ìš”ì„±**: ì˜¤ë˜ëœ ë°ì´í„°ëŠ” í˜„ì¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê²°ì •ì— ë¶€ì í•©

#### 2.1.5 ìœ íš¨ì„± (Validity)
- **ì •ì˜**: ë°ì´í„°ê°€ ì •ì˜ëœ í˜•ì‹ê³¼ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ì •ë„
- **ì¸¡ì •**: í˜•ì‹ ë¶ˆì¼ì¹˜ìœ¨, ë„ë©”ì¸ ì œì•½ ìœ„ë°˜ë¥ 
- **ì¤‘ìš”ì„±**: ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°ëŠ” ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¥¼ ì•¼ê¸°

#### 2.1.6 ê³ ìœ ì„± (Uniqueness)
- **ì •ì˜**: ë°ì´í„°ì— ì¤‘ë³µì´ ì—†ëŠ” ì •ë„
- **ì¸¡ì •**: ì¤‘ë³µ ë ˆì½”ë“œ ë¹„ìœ¨, í‚¤ ì¤‘ë³µë¥ 
- **ì¤‘ìš”ì„±**: ì¤‘ë³µ ë°ì´í„°ëŠ” í†µê³„ë¥¼ ì™œê³¡í•˜ê³  ì €ì¥ ê³µê°„ì„ ë‚­ë¹„

### 2.2 ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ê°œë…

ë°ì´í„° í”„ë¡œíŒŒì¼ë§ì€ ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì¡°ì‚¬í•˜ì—¬ êµ¬ì¡°, ë‚´ìš©, ê´€ê³„, í’ˆì§ˆì„ ì´í•´í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.

#### 2.2.1 ë‹¨ë³€ëŸ‰ í”„ë¡œíŒŒì¼ë§
ê° ì»¬ëŸ¼ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„:
- ê¸°ë³¸ í†µê³„ (í‰ê· , ì¤‘ì•™ê°’, í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’)
- ë¶„í¬ íŠ¹ì„± (ì™œë„, ì²¨ë„)
- ê²°ì¸¡ê°’ ë° ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜
- ë°ì´í„° íƒ€ì… ë° í˜•ì‹

#### 2.2.2 ë‹¤ë³€ëŸ‰ í”„ë¡œíŒŒì¼ë§
ì—¬ëŸ¬ ì»¬ëŸ¼ ê°„ì˜ ê´€ê³„ ë¶„ì„:
- ìƒê´€ê´€ê³„
- ê³µë™ ë°œìƒ íŒ¨í„´
- í•¨ìˆ˜ì  ì˜ì¡´ì„±
- êµì°¨ í•„ë“œ ì¼ê´€ì„±

#### 2.2.3 ë©”íƒ€ë°ì´í„° í”„ë¡œíŒŒì¼ë§
ë°ì´í„°ì— ëŒ€í•œ ë©”íƒ€ ì •ë³´:
- ìŠ¤í‚¤ë§ˆ êµ¬ì¡°
- ë°ì´í„° ê³„ë³´ (lineage)
- ì—…ë°ì´íŠ¸ ë¹ˆë„
- ë°ì´í„° ì¶œì²˜

### 2.3 ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ì „ììƒê±°ë˜ ê³ ê° ë°ì´í„°
**ìƒí™©**: 100ë§Œ ê±´ì˜ ê³ ê° í”„ë¡œí•„ ë°ì´í„° ìˆ˜ë ¹
**í’ˆì§ˆ ì´ìŠˆ**:
- ì´ë©”ì¼ í•„ë“œ 15% ê²°ì¸¡
- ìƒë…„ì›”ì¼ê³¼ ë‚˜ì´ ë¶ˆì¼ì¹˜ 3,542ê±´
- ì¤‘ë³µ ê³ ê° ID 87ê±´
- ì „í™”ë²ˆí˜¸ í˜•ì‹ ë¶ˆì¼ì¹˜ (ë‹¤ì–‘í•œ í¬ë§·)

**í‰ê°€ ê²°ê³¼**:
- ì™„ì „ì„±: 85% (ì´ë©”ì¼ ê²°ì¸¡ìœ¼ë¡œ ì¸í•œ ê°ì )
- ì •í™•ì„±: 96% (ë‚˜ì´ ë¶ˆì¼ì¹˜)
- ì¼ê´€ì„±: 99.9% (ì¤‘ë³µ ID)
- ìœ íš¨ì„±: 92% (ì „í™”ë²ˆí˜¸ í˜•ì‹)

**ê¶Œì¥ ì¡°ì¹˜**:
1. ì´ë©”ì¼ ê²°ì¸¡ê°’ ì²˜ë¦¬ (ê³ ìš°ì„ ìˆœìœ„)
2. ë‚˜ì´-ìƒë…„ì›”ì¼ ë¶ˆì¼ì¹˜ í•´ê²°
3. ì¤‘ë³µ ID ë³‘í•©
4. ì „í™”ë²ˆí˜¸ í˜•ì‹ í‘œì¤€í™”

#### ì‹œë‚˜ë¦¬ì˜¤ 2: IoT ì„¼ì„œ ë°ì´í„°
**ìƒí™©**: 3ê°œì›”ì¹˜ ì˜¨ë„ ì„¼ì„œ ë°ì´í„° (1,000ë§Œ ê±´)
**í’ˆì§ˆ ì´ìŠˆ**:
- ì„¼ì„œ ì˜¤ë¥˜ë¡œ ì¸í•œ ë¹„í˜„ì‹¤ì  ê°’ (ì˜ˆ: -999, 9999)
- íƒ€ì„ìŠ¤íƒ¬í”„ ì¤‘ë³µ ë° ìˆœì„œ ì˜¤ë¥˜
- íŠ¹ì • ì„¼ì„œì˜ ê°„í—ì  ë°ì´í„° ëˆ„ë½

**í‰ê°€ ê²°ê³¼**:
- ì™„ì „ì„±: 94% (ê°„í—ì  ëˆ„ë½)
- ì •í™•ì„±: 97% (ì˜¤ë¥˜ ê°’)
- ì ì‹œì„±: 100% (ì‹¤ì‹œê°„ ìˆ˜ì§‘)
- ì¼ê´€ì„±: 99% (íƒ€ì„ìŠ¤íƒ¬í”„ ì¤‘ë³µ)

**ê¶Œì¥ ì¡°ì¹˜**:
1. ì„¼ì„œ ì˜¤ë¥˜ ê°’ ì‹ë³„ ë° ì œê±°
2. íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë ¬ ë° ì¤‘ë³µ í•´ê²°
3. ê²°ì¸¡ê°’ ë³´ê°„ (ì‹œê³„ì—´ íŠ¹ì„± ê³ ë ¤)

---

## 3. êµ¬í˜„: ìƒì„¸ Python ì½”ë“œ

### 3.1 ì¢…í•© ë°ì´í„° í”„ë¡œíŒŒì¼ë§

```python
import pandas as pd
import numpy as np
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')

def comprehensive_data_profiling(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Comprehensive data quality profiling
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe to profile
        
    Returns:
    --------
    dict
        Complete profiling report with basic info, quality metrics, and issues
        
    Example:
    --------
    >>> df = pd.read_csv('customer_data.csv')
    >>> profile = comprehensive_data_profiling(df)
    >>> print(profile['basic_info'])
    >>> print(profile['quality_metrics'])
    """
    
    profile = {
        'basic_info': {},
        'quality_metrics': pd.DataFrame(),
        'issues': [],
        'recommendations': []
    }
    
    # ===== 1. ê¸°ë³¸ ì •ë³´ =====
    profile['basic_info'] = {
        'n_rows': len(df),
        'n_columns': len(df.columns),
        'memory_mb': round(df.memory_usage(deep=True).sum() / 1024**2, 2),
        'duplicate_rows': df.duplicated().sum(),
        'duplicate_rows_pct': round(100 * df.duplicated().sum() / len(df), 2),
        'total_cells': df.size,
        'total_missing_cells': df.isnull().sum().sum(),
        'overall_missing_pct': round(100 * df.isnull().sum().sum() / df.size, 2)
    }
    
    # ===== 2. ì»¬ëŸ¼ë³„ í’ˆì§ˆ ë©”íŠ¸ë¦­ =====
    quality_report = []
    
    for col in df.columns:
        col_info = {
            'column': col,
            'dtype': str(df[col].dtype),
            'missing_count': df[col].isnull().sum(),
            'missing_pct': round(100 * df[col].isnull().sum() / len(df), 2),
            'unique_count': df[col].nunique(),
            'unique_pct': round(100 * df[col].nunique() / len(df), 2),
            'cardinality': 'high' if df[col].nunique() > len(df) * 0.5 else 
                          ('medium' if df[col].nunique() > 10 else 'low')
        }
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì¶”ê°€ ì •ë³´
        if pd.api.types.is_numeric_dtype(df[col]):
            non_null_values = df[col].dropna()
            if len(non_null_values) > 0:
                col_info.update({
                    'mean': round(non_null_values.mean(), 2),
                    'std': round(non_null_values.std(), 2),
                    'min': non_null_values.min(),
                    'q25': round(non_null_values.quantile(0.25), 2),
                    'median': round(non_null_values.median(), 2),
                    'q75': round(non_null_values.quantile(0.75), 2),
                    'max': non_null_values.max(),
                    'zeros_count': (df[col] == 0).sum(),
                    'zeros_pct': round(100 * (df[col] == 0).sum() / len(df), 2),
                    'negative_count': (df[col] < 0).sum(),
                    'negative_pct': round(100 * (df[col] < 0).sum() / len(df), 2),
                    'skewness': round(non_null_values.skew(), 2),
                    'kurtosis': round(non_null_values.kurtosis(), 2)
                })
        
        # ë¬¸ìì—´ ë³€ìˆ˜ ì¶”ê°€ ì •ë³´
        elif pd.api.types.is_string_dtype(df[col]) or df[col].dtype == 'object':
            non_null_values = df[col].dropna()
            if len(non_null_values) > 0:
                col_info.update({
                    'avg_length': round(non_null_values.astype(str).str.len().mean(), 2),
                    'max_length': non_null_values.astype(str).str.len().max(),
                    'min_length': non_null_values.astype(str).str.len().min(),
                    'has_whitespace': non_null_values.astype(str).str.contains(r'^\s|\s$').any(),
                    'has_special_chars': non_null_values.astype(str).str.contains(r'[^a-zA-Z0-9\s]').any()
                })
        
        # ë‚ ì§œ/ì‹œê°„ ë³€ìˆ˜ ì¶”ê°€ ì •ë³´
        elif pd.api.types.is_datetime64_any_dtype(df[col]):
            non_null_values = df[col].dropna()
            if len(non_null_values) > 0:
                col_info.update({
                    'min_date': non_null_values.min(),
                    'max_date': non_null_values.max(),
                    'date_range_days': (non_null_values.max() - non_null_values.min()).days
                })
        
        quality_report.append(col_info)
    
    profile['quality_metrics'] = pd.DataFrame(quality_report)
    
    # ===== 3. í’ˆì§ˆ ì´ìŠˆ ì‹ë³„ =====
    
    # 3.1 ê²°ì¸¡ê°’ ì´ìŠˆ
    for col in df.columns:
        missing_pct = 100 * df[col].isnull().sum() / len(df)
        
        if missing_pct > 50:
            profile['issues'].append({
                'severity': 'HIGH',
                'category': 'Missing Data',
                'column': col,
                'issue': f'Critical missing rate: {missing_pct:.1f}%',
                'impact': 'Column may need to be dropped or requires domain expertise for imputation'
            })
            profile['recommendations'].append(f"Consider dropping '{col}' or consult domain expert")
            
        elif missing_pct > 20:
            profile['issues'].append({
                'severity': 'MEDIUM',
                'category': 'Missing Data',
                'column': col,
                'issue': f'Moderate missing rate: {missing_pct:.1f}%',
                'impact': 'Imputation required, may introduce bias'
            })
            profile['recommendations'].append(f"Apply appropriate imputation strategy for '{col}'")
            
        elif missing_pct > 5:
            profile['issues'].append({
                'severity': 'LOW',
                'category': 'Missing Data',
                'column': col,
                'issue': f'Minor missing rate: {missing_pct:.1f}%',
                'impact': 'Minimal impact, simple imputation sufficient'
            })
    
    # 3.2 ì¤‘ë³µ ì´ìŠˆ
    if profile['basic_info']['duplicate_rows'] > 0:
        dup_pct = profile['basic_info']['duplicate_rows_pct']
        severity = 'HIGH' if dup_pct > 5 else ('MEDIUM' if dup_pct > 1 else 'LOW')
        
        profile['issues'].append({
            'severity': severity,
            'category': 'Duplicates',
            'column': 'ALL',
            'issue': f'Duplicate rows detected: {profile["basic_info"]["duplicate_rows"]} ({dup_pct:.2f}%)',
            'impact': 'May skew statistical analysis and model training'
        })
        profile['recommendations'].append("Investigate and remove duplicate rows")
    
    # 3.3 ì¹´ë””ë„ë¦¬í‹° ì´ìŠˆ
    for col in df.columns:
        unique_pct = 100 * df[col].nunique() / len(df)
        
        # ê±°ì˜ ëª¨ë“  ê°’ì´ ìœ ë‹ˆí¬ (ID í•„ë“œì¼ ê°€ëŠ¥ì„±)
        if unique_pct > 95 and not col.lower().endswith('id'):
            profile['issues'].append({
                'severity': 'LOW',
                'category': 'Cardinality',
                'column': col,
                'issue': f'Very high cardinality: {df[col].nunique()} unique values ({unique_pct:.1f}%)',
                'impact': 'May not be useful for analysis, consider if this is an identifier'
            })
        
        # ê±°ì˜ ëª¨ë“  ê°’ì´ ë™ì¼ (ìƒìˆ˜ í•„ë“œ)
        elif unique_pct < 1 and df[col].nunique() > 1:
            profile['issues'].append({
                'severity': 'MEDIUM',
                'category': 'Cardinality',
                'column': col,
                'issue': f'Very low cardinality: {df[col].nunique()} unique values ({unique_pct:.1f}%)',
                'impact': 'Low information content, consider dropping'
            })
            profile['recommendations'].append(f"Consider dropping low-variance column '{col}'")
        
        # ì™„ì „ ìƒìˆ˜ í•„ë“œ
        elif df[col].nunique() == 1:
            profile['issues'].append({
                'severity': 'HIGH',
                'category': 'Cardinality',
                'column': col,
                'issue': 'Constant column (only 1 unique value)',
                'impact': 'Zero information content, should be dropped'
            })
            profile['recommendations'].append(f"Drop constant column '{col}'")
    
    # 3.4 ë°ì´í„° íƒ€ì… ì´ìŠˆ
    for col in df.columns:
        # ìˆ«ìì²˜ëŸ¼ ë³´ì´ëŠ” ë¬¸ìì—´
        if df[col].dtype == 'object':
            sample = df[col].dropna().head(100)
            if len(sample) > 0:
                try:
                    # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                    pd.to_numeric(sample, errors='raise')
                    profile['issues'].append({
                        'severity': 'MEDIUM',
                        'category': 'Data Type',
                        'column': col,
                        'issue': 'Numeric data stored as string',
                        'impact': 'Inefficient storage, incorrect operations'
                    })
                    profile['recommendations'].append(f"Convert '{col}' to numeric type")
                except:
                    pass
    
    return profile


def print_profile_summary(profile: Dict[str, Any]) -> None:
    """
    Print a human-readable summary of the profile report
    
    Parameters:
    -----------
    profile : dict
        Profile report from comprehensive_data_profiling()
    """
    
    print("=" * 80)
    print("DATA QUALITY ASSESSMENT REPORT")
    print("=" * 80)
    
    print("\nğŸ“Š BASIC INFORMATION")
    print("-" * 80)
    for key, value in profile['basic_info'].items():
        print(f"{key:.<40} {value}")
    
    print("\n\nğŸ“ˆ QUALITY METRICS BY COLUMN")
    print("-" * 80)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    print(profile['quality_metrics'].to_string(index=False))
    
    print("\n\nâš ï¸  QUALITY ISSUES")
    print("-" * 80)
    if len(profile['issues']) == 0:
        print("âœ“ No significant quality issues detected!")
    else:
        # Group by severity
        for severity in ['HIGH', 'MEDIUM', 'LOW']:
            severity_issues = [i for i in profile['issues'] if i['severity'] == severity]
            if severity_issues:
                print(f"\n{severity} SEVERITY ({len(severity_issues)} issues):")
                for issue in severity_issues:
                    print(f"  â€¢ [{issue['category']}] {issue['column']}: {issue['issue']}")
                    print(f"    Impact: {issue['impact']}")
    
    print("\n\nğŸ’¡ RECOMMENDATIONS")
    print("-" * 80)
    if len(profile['recommendations']) == 0:
        print("âœ“ No specific recommendations")
    else:
        for i, rec in enumerate(profile['recommendations'], 1):
            print(f"{i}. {rec}")
    
    print("\n" + "=" * 80)
```

### 3.2 ë°ì´í„° íƒ€ì… ê²€ì¦

```python
from typing import Union, Callable

def validate_data_types(df: pd.DataFrame, 
                       expected_types: Dict[str, Union[str, Callable]]) -> pd.DataFrame:
    """
    Validate data types against expected schema
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe
    expected_types : dict
        Dictionary mapping column names to expected types.
        Values can be:
        - String: 'numeric', 'datetime', 'categorical', 'string', 'boolean'
        - Callable: Custom validation function returning bool
        
    Returns:
    --------
    pd.DataFrame
        Report of type validation issues
        
    Example:
    --------
    >>> expected_schema = {
    ...     'user_id': 'numeric',
    ...     'signup_date': 'datetime',
    ...     'age': 'numeric',
    ...     'category': 'categorical',
    ...     'email': 'string',
    ...     'is_active': 'boolean'
    ... }
    >>> issues = validate_data_types(df, expected_schema)
    >>> print(issues)
    """
    
    type_issues = []
    
    for col, expected_type in expected_types.items():
        # Check if column exists
        if col not in df.columns:
            type_issues.append({
                'column': col,
                'expected_type': expected_type,
                'actual_type': 'N/A',
                'issue': 'Column not found in dataframe',
                'severity': 'HIGH',
                'suggestion': 'Check column name spelling or data source'
            })
            continue
        
        actual_type = str(df[col].dtype)
        is_valid = True
        issue_message = None
        suggestion = None
        
        # Type validation based on expected type
        if isinstance(expected_type, str):
            if expected_type == 'numeric':
                if not pd.api.types.is_numeric_dtype(df[col]):
                    is_valid = False
                    issue_message = f'Not numeric type (found: {actual_type})'
                    suggestion = f"Convert using: df['{col}'] = pd.to_numeric(df['{col}'], errors='coerce')"
            
            elif expected_type == 'datetime':
                if not pd.api.types.is_datetime64_any_dtype(df[col]):
                    is_valid = False
                    issue_message = f'Not datetime type (found: {actual_type})'
                    suggestion = f"Convert using: df['{col}'] = pd.to_datetime(df['{col}'], errors='coerce')"
            
            elif expected_type == 'categorical':
                if df[col].dtype != 'category':
                    # This is often a warning rather than error
                    is_valid = False
                    issue_message = f'Not categorical type (found: {actual_type})'
                    suggestion = f"Convert using: df['{col}'] = df['{col}'].astype('category')"
            
            elif expected_type == 'string':
                if not (pd.api.types.is_string_dtype(df[col]) or df[col].dtype == 'object'):
                    is_valid = False
                    issue_message = f'Not string/object type (found: {actual_type})'
                    suggestion = f"Convert using: df['{col}'] = df['{col}'].astype(str)"
            
            elif expected_type == 'boolean':
                if df[col].dtype != 'bool':
                    is_valid = False
                    issue_message = f'Not boolean type (found: {actual_type})'
                    suggestion = f"Convert using: df['{col}'] = df['{col}'].astype(bool)"
        
        elif callable(expected_type):
            # Custom validation function
            try:
                is_valid = expected_type(df[col])
                if not is_valid:
                    issue_message = 'Failed custom validation'
                    suggestion = 'Check custom validation function requirements'
            except Exception as e:
                is_valid = False
                issue_message = f'Custom validation error: {str(e)}'
                suggestion = 'Review custom validation function'
        
        # Record issue if validation failed
        if not is_valid:
            type_issues.append({
                'column': col,
                'expected_type': expected_type,
                'actual_type': actual_type,
                'issue': issue_message,
                'severity': 'HIGH',
                'suggestion': suggestion
            })
    
    return pd.DataFrame(type_issues)


def auto_detect_types(df: pd.DataFrame, 
                     sample_size: int = 1000) -> Dict[str, str]:
    """
    Automatically detect appropriate data types for each column
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe
    sample_size : int
        Number of rows to sample for detection
        
    Returns:
    --------
    dict
        Suggested types for each column
        
    Example:
    --------
    >>> detected_types = auto_detect_types(df)
    >>> print(detected_types)
    {'user_id': 'numeric', 'name': 'string', 'signup_date': 'datetime', ...}
    """
    
    suggested_types = {}
    sample_df = df.head(sample_size) if len(df) > sample_size else df
    
    for col in df.columns:
        sample = sample_df[col].dropna()
        
        if len(sample) == 0:
            suggested_types[col] = 'unknown'
            continue
        
        # Check if numeric
        try:
            pd.to_numeric(sample, errors='raise')
            suggested_types[col] = 'numeric'
            continue
        except:
            pass
        
        # Check if datetime
        try:
            pd.to_datetime(sample, errors='raise')
            suggested_types[col] = 'datetime'
            continue
        except:
            pass
        
        # Check if boolean
        unique_values = set(sample.astype(str).str.lower())
        if unique_values.issubset({'true', 'false', '1', '0', 'yes', 'no', 't', 'f', 'y', 'n'}):
            suggested_types[col] = 'boolean'
            continue
        
        # Check if categorical (low cardinality)
        if sample.nunique() < 20:
            suggested_types[col] = 'categorical'
        else:
            suggested_types[col] = 'string'
    
    return suggested_types
```

### 3.3 ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦

```python
from typing import Callable, Tuple
import re

class BusinessRuleValidator:
    """
    Validates business rules on dataframes
    """
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.violations = []
    
    def add_rule(self, 
                 rule_name: str,
                 validation_func: Callable[[pd.DataFrame], pd.Series],
                 severity: str = 'MEDIUM',
                 description: str = '') -> 'BusinessRuleValidator':
        """
        Add a business rule to validate
        
        Parameters:
        -----------
        rule_name : str
            Name of the rule
        validation_func : callable
            Function that takes df and returns boolean Series (True = valid)
        severity : str
            'HIGH', 'MEDIUM', or 'LOW'
        description : str
            Human-readable description of the rule
            
        Returns:
        --------
        self
            For method chaining
        """
        
        try:
            # Apply validation function
            valid_mask = validation_func(self.df)
            invalid_mask = ~valid_mask
            
            violations_count = invalid_mask.sum()
            
            if violations_count > 0:
                violation_indices = self.df[invalid_mask].index.tolist()
                
                self.violations.append({
                    'rule': rule_name,
                    'description': description,
                    'severity': severity,
                    'violations_count': violations_count,
                    'violations_pct': round(100 * violations_count / len(self.df), 2),
                    'violation_indices': violation_indices[:100],  # Store first 100
                    'examples': self.df[invalid_mask].head(5).to_dict('records')
                })
        
        except Exception as e:
            self.violations.append({
                'rule': rule_name,
                'description': description,
                'severity': 'HIGH',
                'violations_count': 'ERROR',
                'violations_pct': 'N/A',
                'error': str(e)
            })
        
        return self
    
    def get_report(self) -> pd.DataFrame:
        """Get violations report as dataframe"""
        if not self.violations:
            return pd.DataFrame()
        
        # Remove large fields for display
        report_data = []
        for v in self.violations:
            report_row = {k: v[k] for k in v if k not in ['violation_indices', 'examples']}
            report_data.append(report_row)
        
        return pd.DataFrame(report_data)
    
    def get_detailed_violations(self, rule_name: str) -> Dict[str, Any]:
        """Get detailed information about specific rule violations"""
        for v in self.violations:
            if v['rule'] == rule_name:
                return v
        return None


def validate_business_rules(df: pd.DataFrame) -> List[Dict[str, Any]]:
    """
    Validate common business rules
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe
        
    Returns:
    --------
    list
        List of violation dictionaries
        
    Example:
    --------
    >>> violations = validate_business_rules(df)
    >>> for v in violations:
    ...     print(f"{v['rule']}: {v['violations_count']} violations")
    """
    
    validator = BusinessRuleValidator(df)
    
    # Rule 1: Age must be between 0 and 120
    if 'age' in df.columns:
        validator.add_rule(
            rule_name='Valid Age Range',
            validation_func=lambda d: (d['age'] >= 0) & (d['age'] <= 120),
            severity='HIGH',
            description='Age must be between 0 and 120'
        )
    
    # Rule 2: Email format validation
    if 'email' in df.columns:
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        validator.add_rule(
            rule_name='Valid Email Format',
            validation_func=lambda d: d['email'].astype(str).str.match(email_pattern, na=False),
            severity='MEDIUM',
            description='Email must follow standard format'
        )
    
    # Rule 3: Date must not be in the future
    if 'date' in df.columns:
        validator.add_rule(
            rule_name='Date Not in Future',
            validation_func=lambda d: pd.to_datetime(d['date'], errors='coerce') <= pd.Timestamp.now(),
            severity='HIGH',
            description='Date cannot be in the future'
        )
    
    # Rule 4: Start date before end date
    if 'start_date' in df.columns and 'end_date' in df.columns:
        validator.add_rule(
            rule_name='Start Before End',
            validation_func=lambda d: pd.to_datetime(d['start_date'], errors='coerce') <= 
                                     pd.to_datetime(d['end_date'], errors='coerce'),
            severity='HIGH',
            description='Start date must be before end date'
        )
    
    # Rule 5: Age matches birth date (if both present)
    if 'age' in df.columns and 'birth_date' in df.columns:
        def check_age_birthdate(d):
            calculated_age = (pd.Timestamp.now() - pd.to_datetime(d['birth_date'], errors='coerce')).dt.days / 365.25
            age_diff = abs(d['age'] - calculated_age)
            return age_diff <= 1  # Allow 1 year tolerance
        
        validator.add_rule(
            rule_name='Age Matches Birth Date',
            validation_func=check_age_birthdate,
            severity='MEDIUM',
            description='Age should match calculated age from birth date'
        )
    
    # Rule 6: Positive values for price/amount
    for col in ['price', 'amount', 'cost', 'total']:
        if col in df.columns:
            validator.add_rule(
                rule_name=f'Positive {col.title()}',
                validation_func=lambda d, c=col: d[c] >= 0,
                severity='HIGH',
                description=f'{col.title()} must be non-negative'
            )
    
    # Rule 7: Phone number format (flexible)
    if 'phone' in df.columns:
        # Remove non-digits and check length
        def check_phone(d):
            digits_only = d['phone'].astype(str).str.replace(r'\D', '', regex=True)
            return digits_only.str.len().between(10, 15)
        
        validator.add_rule(
            rule_name='Valid Phone Number',
            validation_func=check_phone,
            severity='LOW',
            description='Phone number should have 10-15 digits'
        )
    
    return validator.violations
```

### 3.4 ìë™ í”„ë¡œíŒŒì¼ë§ (ydata-profiling)

```python
def generate_auto_profile_report(df: pd.DataFrame,
                                 output_file: str = 'profile_report.html',
                                 title: str = 'Data Profile Report',
                                 minimal: bool = False) -> None:
    """
    Generate automated profiling report using ydata-profiling
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe
    output_file : str
        Output HTML file path
    title : str
        Report title
    minimal : bool
        If True, generate minimal report (faster)
        
    Example:
    --------
    >>> generate_auto_profile_report(df, 'customer_profile.html')
    """
    
    try:
        from ydata_profiling import ProfileReport
    except ImportError:
        print("ydata-profiling not installed. Install with: pip install ydata-profiling")
        return
    
    # Configure profile settings
    if minimal:
        profile = ProfileReport(
            df,
            title=title,
            minimal=True,
            explorative=False
        )
    else:
        profile = ProfileReport(
            df,
            title=title,
            explorative=True,
            correlations={
                "auto": {"calculate": True},
                "pearson": {"calculate": True},
                "spearman": {"calculate": True},
                "kendall": {"calculate": False},  # Slow for large datasets
                "phi_k": {"calculate": True},
                "cramers": {"calculate": True},
            },
            missing_diagrams={
                "bar": True,
                "matrix": True,
                "heatmap": True,
                "dendrogram": True,
            },
            duplicates={
                "head": 10,
                "key": None,  # Auto-detect key columns
            },
            samples={
                "head": 10,
                "tail": 10,
                "random": 10
            }
        )
    
    # Generate report
    profile.to_file(output_file)
    print(f"âœ“ Profile report generated: {output_file}")
    
    # Also return profile object for programmatic access
    return profile
```

### 3.5 í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

```python
def calculate_data_quality_score(df: pd.DataFrame,
                                 weights: Dict[str, float] = None) -> Dict[str, float]:
    """
    Calculate overall data quality score
    
    Parameters:
    -----------
    df : pd.DataFrame
        Input dataframe
    weights : dict, optional
        Custom weights for each dimension
        Default: {'completeness': 0.3, 'validity': 0.25, 'consistency': 0.25, 
                 'uniqueness': 0.2}
        
    Returns:
    --------
    dict
        Quality scores for each dimension and overall score
        
    Example:
    --------
    >>> scores = calculate_data_quality_score(df)
    >>> print(f"Overall Quality Score: {scores['overall']:.1f}/100")
    """
    
    if weights is None:
        weights = {
            'completeness': 0.3,
            'validity': 0.25,
            'consistency': 0.25,
            'uniqueness': 0.2
        }
    
    scores = {}
    
    # 1. Completeness Score (0-100)
    total_cells = df.size
    missing_cells = df.isnull().sum().sum()
    scores['completeness'] = 100 * (1 - missing_cells / total_cells)
    
    # 2. Validity Score (simplified - based on numeric ranges)
    validity_score = 100.0
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        # Check for unrealistic values (e.g., negative ages)
        if 'age' in col.lower():
            invalid = ((df[col] < 0) | (df[col] > 120)).sum()
            validity_score -= (invalid / len(df)) * 10  # Penalize
    
    scores['validity'] = max(0, validity_score)
    
    # 3. Consistency Score (based on duplicates)
    duplicate_count = df.duplicated().sum()
    scores['consistency'] = 100 * (1 - duplicate_count / len(df))
    
    # 4. Uniqueness Score (based on appropriate uniqueness)
    uniqueness_score = 100.0
    for col in df.columns:
        unique_pct = df[col].nunique() / len(df)
        
        # Constant columns (bad)
        if unique_pct < 0.01:
            uniqueness_score -= 10
        
        # Near-constant columns (bad)
        elif unique_pct < 0.05:
            uniqueness_score -= 5
    
    scores['uniqueness'] = max(0, uniqueness_score)
    
    # 5. Calculate overall score
    scores['overall'] = sum(scores[k] * weights[k] for k in weights.keys())
    
    # Round all scores
    scores = {k: round(v, 2) for k, v in scores.items()}
    
    return scores


def quality_score_interpretation(score: float) -> Tuple[str, str]:
    """
    Interpret quality score
    
    Returns:
    --------
    tuple
        (grade, interpretation)
    """
    if score >= 90:
        return "A", "Excellent - Data is ready for analysis"
    elif score >= 80:
        return "B", "Good - Minor cleaning recommended"
    elif score >= 70:
        return "C", "Fair - Significant cleaning required"
    elif score >= 60:
        return "D", "Poor - Extensive cleaning required"
    else:
        return "F", "Critical - Data quality is unacceptable"
```

---

## 4. ì˜ˆì‹œ: ì…ì¶œë ¥ ìƒ˜í”Œ ë° ì‹œê°í™”

### 4.1 ìƒ˜í”Œ ë°ì´í„° ìƒì„±

```python
# Create sample customer dataset with quality issues
np.random.seed(42)

n_samples = 1000

sample_data = {
    'customer_id': range(1, n_samples + 1),
    'name': [f'Customer_{i}' if i % 50 != 0 else None for i in range(n_samples)],
    'age': [np.random.randint(18, 80) if i % 20 != 0 else 
            (np.random.randint(-5, 0) if i % 100 == 0 else None) 
            for i in range(n_samples)],
    'email': [f'user{i}@example.com' if i % 30 != 0 else 
              (f'invalid_email_{i}' if i % 15 == 0 else None)
              for i in range(n_samples)],
    'signup_date': pd.date_range('2020-01-01', periods=n_samples, freq='D'),
    'purchase_amount': [np.random.uniform(10, 1000) if i % 25 != 0 else None 
                       for i in range(n_samples)],
    'category': np.random.choice(['A', 'B', 'C', 'D'], n_samples)
}

# Add some duplicates
sample_df = pd.DataFrame(sample_data)
sample_df = pd.concat([sample_df, sample_df.iloc[:10]], ignore_index=True)

print("Sample dataset created with intentional quality issues:")
print(f"- {sample_df['name'].isnull().sum()} missing names")
print(f"- {sample_df['age'].isnull().sum()} missing ages")
print(f"- {(sample_df['age'] < 0).sum()} negative ages")
print(f"- {sample_df['email'].isnull().sum()} missing emails")
print(f"- {sample_df.duplicated().sum()} duplicate rows")
```

### 4.2 í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰ ì˜ˆì‹œ

```python
# Run comprehensive profiling
profile = comprehensive_data_profiling(sample_df)
print_profile_summary(profile)
```

**ì˜ˆìƒ ì¶œë ¥**:

```
================================================================================
DATA QUALITY ASSESSMENT REPORT
================================================================================

ğŸ“Š BASIC INFORMATION
--------------------------------------------------------------------------------
n_rows...................................... 1010
n_columns................................... 7
memory_mb................................... 0.05
duplicate_rows.............................. 10
duplicate_rows_pct.......................... 0.99
total_cells................................. 7070
total_missing_cells......................... 118
overall_missing_pct......................... 1.67

ğŸ“ˆ QUALITY METRICS BY COLUMN
--------------------------------------------------------------------------------
        column        dtype  missing_count  missing_pct  unique_count  unique_pct  ...
   customer_id        int64              0         0.00          1010      100.00  ...
          name       object             20         1.98           980       97.03  ...
           age      float64             50         4.95            64        6.34  ...
         email       object             33         3.27           944       93.47  ...
   signup_date  datetime64              0         0.00          1000       99.01  ...
purchase_amount    float64             40         3.96           926       91.68  ...
      category       object              0         0.00             4        0.40  ...

âš ï¸  QUALITY ISSUES
--------------------------------------------------------------------------------

HIGH SEVERITY (2 issues):
  â€¢ [Data Type] age: Negative ages detected
    Impact: Invalid data will affect analysis
  â€¢ [Duplicates] ALL: Duplicate rows detected: 10 (0.99%)
    Impact: May skew statistical analysis and model training

MEDIUM SEVERITY (3 issues):
  â€¢ [Missing Data] name: Moderate missing rate: 1.98%
    Impact: Imputation required, may introduce bias
  â€¢ [Missing Data] email: Moderate missing rate: 3.27%
    Impact: Imputation required, may introduce bias
  â€¢ [Missing Data] age: Moderate missing rate: 4.95%
    Impact: Imputation required, may introduce bias

ğŸ’¡ RECOMMENDATIONS
--------------------------------------------------------------------------------
1. Investigate and remove duplicate rows
2. Apply appropriate imputation strategy for 'name'
3. Apply appropriate imputation strategy for 'email'
4. Apply appropriate imputation strategy for 'age'

================================================================================
```

### 4.3 ì‹œê°í™” ì˜ˆì‹œ

```python
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_quality_metrics(profile: Dict[str, Any]) -> None:
    """
    Visualize quality metrics from profile
    """
    
    metrics_df = profile['quality_metrics']
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Missing data percentage
    missing_data = metrics_df[['column', 'missing_pct']].sort_values('missing_pct', ascending=False)
    axes[0, 0].barh(missing_data['column'], missing_data['missing_pct'], color='coral')
    axes[0, 0].set_xlabel('Missing %')
    axes[0, 0].set_title('Missing Data by Column')
    axes[0, 0].grid(axis='x', alpha=0.3)
    
    # 2. Unique value percentage
    unique_data = metrics_df[['column', 'unique_pct']].sort_values('unique_pct', ascending=False)
    axes[0, 1].barh(unique_data['column'], unique_data['unique_pct'], color='skyblue')
    axes[0, 1].set_xlabel('Unique %')
    axes[0, 1].set_title('Cardinality by Column')
    axes[0, 1].grid(axis='x', alpha=0.3)
    
    # 3. Issue severity distribution
    issues_df = pd.DataFrame(profile['issues'])
    if len(issues_df) > 0:
        severity_counts = issues_df['severity'].value_counts()
        colors = {'HIGH': 'red', 'MEDIUM': 'orange', 'LOW': 'yellow'}
        axes[1, 0].pie(severity_counts, labels=severity_counts.index, autopct='%1.1f%%',
                      colors=[colors[s] for s in severity_counts.index])
        axes[1, 0].set_title('Issues by Severity')
    
    # 4. Quality score breakdown
    scores = calculate_data_quality_score(sample_df)
    score_types = ['completeness', 'validity', 'consistency', 'uniqueness']
    score_values = [scores[t] for t in score_types]
    axes[1, 1].bar(score_types, score_values, color=['green', 'blue', 'purple', 'orange'])
    axes[1, 1].set_ylim(0, 100)
    axes[1, 1].set_ylabel('Score (0-100)')
    axes[1, 1].set_title(f'Quality Score Breakdown (Overall: {scores["overall"]:.1f})')
    axes[1, 1].grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('quality_assessment_visualization.png', dpi=300, bbox_inches='tight')
    plt.show()

# Generate visualization
visualize_quality_metrics(profile)
```

---

## 5. ì—ì´ì „íŠ¸ ë§¤í•‘

### 5.1 Primary Agent: `data-cleaning-specialist`

**ì—­í• **:
- ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬
- í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰ ë° ê²°ê³¼ í•´ì„
- í’ˆì§ˆ ì´ìŠˆ ì‹ë³„ ë° ë¶„ë¥˜
- íƒ€ì… ê²€ì¦ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ ìˆ˜í–‰

**ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜**:
- `comprehensive_data_profiling()`
- `validate_data_types()`
- `validate_business_rules()`
- `calculate_data_quality_score()`

### 5.2 Supporting Agent: `data-scientist`

**ì—­í• **:
- ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì •ì˜
- í’ˆì§ˆ í‰ê°€ ê²°ê³¼ì˜ í†µê³„ì  í•´ì„
- ë°ì´í„° í’ˆì§ˆì´ ë¶„ì„ ë° ëª¨ë¸ë§ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í‰ê°€

**ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜**:
- `auto_detect_types()`
- `quality_score_interpretation()`

### 5.3 Supporting Skill: `data-visualization-specialist`

**ì—­í• **:
- í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œê°í™”
- ëŒ€ì‹œë³´ë“œ ìƒì„±

**ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜**:
- `visualize_quality_metrics()`

---

## 6. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

### 6.1 í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬

```bash
# í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install pandas>=2.0.0
pip install numpy>=1.24.0

# ë°ì´í„° í”„ë¡œíŒŒì¼ë§
pip install ydata-profiling>=4.5.0

# ë°ì´í„° ê²€ì¦
pip install great-expectations>=0.18.0

# ì‹œê°í™”
pip install matplotlib>=3.7.0
pip install seaborn>=0.12.0
```

### 6.2 ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ ì£¼ìš” ê¸°ëŠ¥

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë²„ì „ | ì£¼ìš” ìš©ë„ | í•µì‹¬ í•¨ìˆ˜ |
|-----------|------|-----------|----------|
| pandas | >=2.0.0 | ë°ì´í„° ì¡°ì‘, ê¸°ë³¸ í”„ë¡œíŒŒì¼ë§ | `info()`, `describe()`, `isnull()`, `duplicated()` |
| numpy | >=1.24.0 | ìˆ˜ì¹˜ ì—°ì‚° | `mean()`, `std()`, `percentile()` |
| ydata-profiling | >=4.5.0 | ìë™ í”„ë¡œíŒŒì¼ë§ ë¦¬í¬íŠ¸ | `ProfileReport()` |
| great-expectations | >=0.18.0 | ì²´ê³„ì  ë°ì´í„° ê²€ì¦ | `ExpectationSuite()`, `validate()` |
| matplotlib | >=3.7.0 | ì‹œê°í™” | `bar()`, `pie()`, `hist()` |
| seaborn | >=0.12.0 | í†µê³„ ì‹œê°í™” | `heatmap()`, `boxplot()` |

---

## 7. ì²´í¬í¬ì¸íŠ¸

### 7.1 í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë“  ì»¬ëŸ¼ì˜ ê¸°ë³¸ í†µê³„ë¥¼ í™•ì¸í–ˆëŠ”ê°€?
- [ ] ê²°ì¸¡ê°’ íŒ¨í„´ì„ íŒŒì•…í–ˆëŠ”ê°€?
- [ ] ì¤‘ë³µ ë°ì´í„°ë¥¼ ì‹ë³„í–ˆëŠ”ê°€?
- [ ] ì´ìƒì¹˜ í›„ë³´ë¥¼ í™•ì¸í–ˆëŠ”ê°€?
- [ ] ì¹´ë””ë„ë¦¬í‹°ê°€ ì ì ˆí•œê°€?

### 7.2 íƒ€ì… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë“  ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ì´ ì˜ˆìƒê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?
- [ ] íƒ€ì… ë³€í™˜ì´ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì‹ë³„í–ˆëŠ”ê°€?
- [ ] íƒ€ì… ë³€í™˜ ì‹œ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ì„±ì„ í‰ê°€í–ˆëŠ”ê°€?

### 7.3 ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë„ë©”ì¸ë³„ ì œì•½ ì¡°ê±´ì„ ëª¨ë‘ ì •ì˜í–ˆëŠ”ê°€?
- [ ] ê·œì¹™ ìœ„ë°˜ ê±´ìˆ˜ì™€ ë¹„ìœ¨ì„ í™•ì¸í–ˆëŠ”ê°€?
- [ ] ìœ„ë°˜ íŒ¨í„´ì„ ë¶„ì„í–ˆëŠ”ê°€?
- [ ] ìœ„ë°˜ ë°ì´í„° ì²˜ë¦¬ ë°©ì•ˆì„ ìˆ˜ë¦½í–ˆëŠ”ê°€?

### 7.4 í’ˆì§ˆ ì ìˆ˜ í‰ê°€

| ì ìˆ˜ ë²”ìœ„ | ë“±ê¸‰ | í•´ì„ | ì¡°ì¹˜ |
|----------|------|------|------|
| 90-100 | A | ìš°ìˆ˜ | ë¶„ì„ ì¦‰ì‹œ ê°€ëŠ¥ |
| 80-89 | B | ì–‘í˜¸ | ê²½ë¯¸í•œ í´ë Œì§• ê¶Œì¥ |
| 70-79 | C | ë³´í†µ | ìƒë‹¹í•œ í´ë Œì§• í•„ìš” |
| 60-69 | D | ë¯¸í¡ | ê´‘ë²”ìœ„í•œ í´ë Œì§• í•„ìš” |
| <60 | F | ì‹¬ê° | ë°ì´í„° í’ˆì§ˆ ìˆ˜ìš© ë¶ˆê°€ |

---

## 8. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 8.1 ì¼ë°˜ì  ì˜¤ë¥˜ ë° í•´ê²° ë°©ë²•

#### ë¬¸ì œ 1: ë©”ëª¨ë¦¬ ë¶€ì¡± (MemoryError)
**ì¦ìƒ**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ í”„ë¡œíŒŒì¼ë§ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±
**í•´ê²°**:
```python
# ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
chunk_size = 10000
profiles = []

for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    profile = comprehensive_data_profiling(chunk)
    profiles.append(profile)

# í”„ë¡œíŒŒì¼ ë³‘í•©
merged_profile = merge_profiles(profiles)
```

#### ë¬¸ì œ 2: ydata-profilingì´ ëŠë¦¼
**ì¦ìƒ**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ í”„ë¡œíŒŒì¼ ë¦¬í¬íŠ¸ ìƒì„±ì´ ì˜¤ë˜ ê±¸ë¦¼
**í•´ê²°**:
```python
# ìµœì†Œ ëª¨ë“œ ì‚¬ìš©
profile = ProfileReport(df, minimal=True)

# ë˜ëŠ” ìƒ˜í”Œë§
sample_df = df.sample(n=10000, random_state=42)
profile = ProfileReport(sample_df)
```

#### ë¬¸ì œ 3: íƒ€ì… ë³€í™˜ ì‹¤íŒ¨
**ì¦ìƒ**: `pd.to_numeric()` ë˜ëŠ” `pd.to_datetime()` ì‹¤íŒ¨
**í•´ê²°**:
```python
# errors='coerce' ì‚¬ìš©í•˜ì—¬ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ ê°’ì„ NaNìœ¼ë¡œ
df['age'] = pd.to_numeric(df['age'], errors='coerce')

# ë³€í™˜ ì‹¤íŒ¨í•œ ê°’ í™•ì¸
failed_conversions = df[df['age'].isnull() & original_df['age'].notnull()]
print(failed_conversions)
```

#### ë¬¸ì œ 4: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ ì˜¤ë¥˜
**ì¦ìƒ**: ê·œì¹™ ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ
**í•´ê²°**:
```python
# try-except ë¸”ë¡ ì¶”ê°€
try:
    valid_mask = validation_func(df)
except Exception as e:
    print(f"Validation error: {e}")
    valid_mask = pd.Series([False] * len(df))
```

### 8.2 ì„±ëŠ¥ ìµœì í™” íŒ

1. **ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬**:
   - ìƒ˜í”Œë§ í™œìš©: `df.sample(frac=0.1)`
   - ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬: `pd.read_csv(chunksize=...)`
   - Dask ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê³ ë ¤

2. **í”„ë¡œíŒŒì¼ë§ ì†ë„ í–¥ìƒ**:
   - `minimal=True` ì˜µì…˜ ì‚¬ìš©
   - ë¶ˆí•„ìš”í•œ ìƒê´€ê´€ê³„ ê³„ì‚° ë¹„í™œì„±í™”
   - ìƒ˜í”Œ ë°ì´í„°ë¡œ ì´ˆê¸° í‰ê°€

3. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**:
   - ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
   - ì ì ˆí•œ ë°ì´í„° íƒ€ì… ì‚¬ìš© (`int8`, `int16` ë“±)
   - ì¹´í…Œê³ ë¦¬ íƒ€ì… í™œìš©: `astype('category')`

---

## 9. ì°¸ê³  ìë£Œ

### 9.1 ê³µì‹ ë¬¸ì„œ

- **Pandas**: https://pandas.pydata.org/docs/
  - User Guide: Data Quality
  - API Reference: DataFrame methods

- **ydata-profiling**: https://docs.profiling.ydata.ai/
  - Getting Started
  - Advanced Settings
  - API Reference

- **Great Expectations**: https://docs.greatexpectations.io/
  - Core Concepts
  - Expectation Gallery
  - Validation

### 9.2 ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

1. **í•­ìƒ ì›ë³¸ ë°ì´í„° ë³´ì¡´**:
   ```python
   df_original = df.copy()  # ì›ë³¸ ìœ ì§€
   ```

2. **í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ì €ì¥**:
   ```python
   profile_report = comprehensive_data_profiling(df)
   pd.DataFrame(profile_report['quality_metrics']).to_csv('quality_metrics.csv')
   ```

3. **ë²„ì „ ê´€ë¦¬**:
   - í’ˆì§ˆ í‰ê°€ ê²°ê³¼ë¥¼ ë²„ì „ë³„ë¡œ ì €ì¥
   - ì‹œê°„ì— ë”°ë¥¸ í’ˆì§ˆ ë³€í™” ì¶”ì 

4. **ìë™í™”**:
   - ì •ê¸°ì  í’ˆì§ˆ ì ê²€ ìŠ¤ì¼€ì¤„ë§
   - í’ˆì§ˆ ì €í•˜ ì‹œ ì•Œë¦¼ ì„¤ì •

### 9.3 ì¶”ê°€ í•™ìŠµ ìë£Œ

- **ë…¼ë¬¸**: 
  - "Data Quality: The Accuracy Dimension" (Wang & Strong, 1996)
  - "A Framework for Data Quality Assessment" (Batini et al., 2009)

- **ë¸”ë¡œê·¸/íŠœí† ë¦¬ì–¼**:
  - Real Python: Data Validation with Pandas
  - Towards Data Science: Complete Guide to Data Profiling

- **ë„ì„œ**:
  - "Python for Data Analysis" by Wes McKinney
  - "Data Quality: The Field Guide" by Thomas C. Redman

---

## 10. ìš”ì•½

ë°ì´í„° í’ˆì§ˆ í‰ê°€ëŠ” ëª¨ë“  ë°ì´í„° í´ë Œì§• í”„ë¡œì íŠ¸ì˜ í•„ìˆ˜ ì‹œì‘ì ì…ë‹ˆë‹¤. ì´ ë ˆí¼ëŸ°ìŠ¤ì—ì„œ ë‹¤ë£¬ ë‚´ìš©:

### í•µì‹¬ í¬ì¸íŠ¸

1. **ì¢…í•© í”„ë¡œíŒŒì¼ë§**: ëª¨ë“  í’ˆì§ˆ ì°¨ì›(ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ì ì‹œì„±, ìœ íš¨ì„±, ê³ ìœ ì„±)ì„ í‰ê°€
2. **íƒ€ì… ê²€ì¦**: ë°ì´í„° íƒ€ì…ì˜ ì¼ê´€ì„±ê³¼ ì ì ˆì„± í™•ì¸
3. **ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™**: ë„ë©”ì¸ë³„ ì œì•½ ì¡°ê±´ê³¼ ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦
4. **ìë™í™”**: ydata-profilingìœ¼ë¡œ ì‹ ì†í•œ ì´ˆê¸° í‰ê°€

### ë‹¤ìŒ ë‹¨ê³„

í’ˆì§ˆ í‰ê°€ ì™„ë£Œ í›„:
1. ì‹ë³„ëœ ì´ìŠˆë¥¼ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë¶„ë¥˜
2. ê° ì´ìŠˆì— ì ì ˆí•œ í´ë Œì§• ì „ëµ ì„ íƒ
3. ê²°ì¸¡ê°’ ì²˜ë¦¬ (Reference 02, 03)
4. ì´ìƒì¹˜ ì²˜ë¦¬ (Reference 04, 05)
5. ì¤‘ë³µ ì²˜ë¦¬ (Reference 07)

### ìë™í™” ì»¤ë§¨ë“œ ì—°ê³„

```bash
# í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
/clean:assess --data customer_data.csv --report quality_report.html

# í‰ê°€ ê²°ê³¼ ê¸°ë°˜ ìë™ í´ë Œì§•
/clean:full --data customer_data.csv --based-on quality_report.json
```

---

**ì‘ì„±ì**: Claude Code  
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-01-25  
**ë‹¤ìŒ ë ˆí¼ëŸ°ìŠ¤**: 02-missing-data-patterns.md
